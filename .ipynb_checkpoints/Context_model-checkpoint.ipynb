{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepcut\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow import keras\n",
    "from pythainlp import word_vector\n",
    "import re,string\n",
    "from pythainlp import word_vector\n",
    "from numpy import argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_msg(msg):\n",
    "    \n",
    "    # ลบ text ที่อยู่ในวงเล็บ <> ทั้งหมด\n",
    "    msg = re.sub(r'<.*?>','', msg)\n",
    "    msg = re.sub(r'\\d+', '',msg)\n",
    "    # ลบ hashtag\n",
    "    msg = re.sub(r'#','',msg)\n",
    "    msg = re.sub(r'-','',msg)\n",
    "    msg = re.sub(r'ฯ','',msg)\n",
    "    msg = re.sub(r'ๆ','',msg)\n",
    "    msg = re.sub(r'!@#$','',msg)\n",
    "    msg = re.sub(r'[a-zA-Z]','',msg)\n",
    "    # ลบ เครื่องหมายคำพูด (punctuation)\n",
    "    for c in string.punctuation:\n",
    "        msg = re.sub(r'\\{}'.format(c),'',msg)\n",
    "    # ลบ separator เช่น \\n \\t\n",
    "    msg = ' '.join(msg.split())\n",
    "    \n",
    "    return msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['พยากรณ์อากาศ', 'ชั่วโมงข้างหน้า', 'บริเวณความกดอากาศสูงหรือมวลอากาศเย็นกำลังปานกลางจากประเทศจีนแผ่ปกคลุมประเทศไทยตอนบน', 'ประกอบกับมีหย่อมความกดอากาศต่ำปกคลุมบริเวณประเทศกัมพูชา', 'ลักษณะเช่นนี้ทำให้ประเทศไทยตอนบนมีฝนเกิดขึ้น', 'กับมีอากาศเย็น', 'ส่วนบริเวณยอดดอยและยอดภู', 'มีอากาศหนาว', 'สำหรับมรสุมตะวันออกเฉียงเหนือพัดปกคลุมอ่าวไทยและภาคใต้', 'ทำให้ภาคใต้มีฝนตกต่อเนื่อง', 'อนึ่ง', 'พายุโซนร้อน', 'อัสนี', 'พายุระดับ', 'บริเวณตะวันตกเฉียงใต้ของเกาะไต้หวัน', 'มีแนวโน้มที่จะอ่อนกำลังลง', 'และไม่มีผลกระทบต่อประเทศไทย', 'ในช่วงวันที่', 'พย', 'บริเวณความกดอากาศสูงหรือมวลอากาศเย็นกำลังปานกลางจากประเทศจีนปกคลุมประเทศไทยตอนบน', 'ประกอบกับมีหย่อมความกดอากาศต่ำปกคลุมบริเวณประเทศกัมพูชา', 'ลักษณะเช่นนี้ทำให้บริเวณประเทศไทยตอนบนมีอากาศเย็นกับมีฝนเล็กน้อยถึงปานกลาง', 'โดยเฉพาะบริเวณภาคตะวันออกเฉียงเหนือตอนล่างและภาคตะวันออก', 'สำหรับภาคใต้ตอนล่างมีฝนตกหนักบางแห่ง', 'เนื่องจากมรสุมตะวันออกเฉียงเหนือพัดปกคลุมอ่าวไทยและภาคใต้', 'ส่วนในช่วงวันที่', 'พย', 'บริเวณความกดอากาศสูงหรือมวลอากาศเย็นกำลังค่อนข้างแรงอีกระลอกจากประเทศจีนจะแผ่เสริมลงมาปกคลุมประเทศไทยตอนบน', 'ทำให้ประเทศไทยตอนบน', 'มีอุณหภูมิลดลง', 'องศาเซลเซียส', 'กับมีอากาศเย็นและมีลมแรง', 'ในขณะที่มรสุมตะวันออกเฉียงเหนือที่พัดปกคลุมอ่าวไทยตอนบนและภาคใต้จะมีกำลังแรงขึ้น', 'ทำให้ภาคใต้ตอนล่างยังคงมีฝนตกหนักบางแห่ง', 'ส่วนคลื่นลมบริเวณอ่าวไทยตอนบนมีกำลังปานกลาง', 'โดยมีคลื่นสูงประมาณ', 'เมตร', 'บริเวณที่มีฝนฟ้าคะนองคลื่นสูงมากกว่า', 'เมตร', 'อนึ่ง', 'สำหรับพายุโซนร้อน', 'อัสนี', 'พายุระดับ', 'ทางเหนือของประเทศฟิลิปปินส์มีแนวโน้มจะอ่อนกำลังลงในช่วงวันที่', 'พย', 'โดยพายุนี้ไม่มีผลกระทบต่อประเทศไทย', 'ส่วนในช่วงวันที่', 'พย', 'จะมีหย่อมความกดอากาศต่ำกำลังแรงเคลื่อนตัวผ่านบริเวณประเทศเวียดนามตอนกลาง', 'ขอให้ประชาชนบริเวณประเทศไทยตอนบนดูแลสุขภาพเนื่องจากสภาพอากาศที่แปรปรวนไว้ด้วย', 'และประชาชนบริเวณภาคใต้ระวังอันตรายจากฝนที่ตกหนักและฝนที่ตกสะสมไว้ด้วย', 'ในช่วงวันที่', 'พย', 'ขอให้เกษตรกรเตรียมการป้องกันและระวังความเสียหายที่จะเกิดต่อผลผลิตทางการเกษตรไว้ด้วย', 'บริเวณความกดอากาศสูงจากประเทศจีนได้แผ่ลงมาปกคลุมภาคเหนือตอนบนและภาคตะวันออกเฉียงเหนือในระยะต้นและกลางช่วงและแผ่ปกคลุมประเทศไทยตอนบนในระยะปลายช่วง', 'ประกอบกับในวันแรกของช่วงมีหย่อมความกดอากาศต่ำปกคลุมอยู่บริเวณภาคเหนือและภาคตะวันออกเฉียงเหนือ', 'ลักษณะดังกล่าวทำให้บริเวณประเทศไทยตอนบนมีอากาศเย็นเกือบทั่วไปในภาคเหนือและภาคตะวันออกเฉียงเหนือ', 'กับมีฝนส่วนมากในระยะต้นช่วง', 'ส่วนภาคใต้มีฝนตลอดช่วงจากอิทธิพลของมรสุมตะวันออกเฉียงเหนือที่พัดปกคลุมอ่าวไทยและภาคใต้เกือบตลอดช่วง', 'ประกอบกับมีร่องมรสุมพาดผ่านภาคใต้ตอนกลางในระยะครึ่งแรกของช่วง', 'จากนั้นได้เลื่อนลงไปพาดผ่านบริเวณภาคใต้ตอนล่าง', 'บริเวณประเทศไทยตอนบน', 'จะมีอากาศหนาวเย็นมากขึ้น', 'โดยเฉพาะในระยะครึ่งหลังของเดือน', 'กับจะมีหมอกหนาหลายพื้นที่ในบางช่วง', 'บริเวณเทือกเขา', 'ยอดดอยและยอดภูจะมีอากาศหนาวถึงหนาวจัดกับมีน้ำค้างแข็งเกิดขึ้นได้ในบางวัน', 'สำหรับภาคใต้ฝั่งตะวันออกยังคงมีฝนตกชุกหนาแน่น', 'กับจะมีฝนตกหนักบางแห่งในบางวัน', 'โดยเฉพาะตั้งแต่จังหวัดสุราษฎร์ธานีลงไป', 'คลื่นลมในทะเลอ่าวไทยยังคงมีกำลังแรง', 'จะมีคลื่นสูง', 'เมตรในบางช่วง', 'ส่วนภาคใต้ฝั่งตะวันตกฝนจะลดลง', 'คลื่นลมทะเลอันดามันจะมีคลื่นสูง', 'เมตร', 'เนื่องจาก', 'บริเวณความกดอากาศสูงจากประเทศจีนยังคงแผ่เสริมลงมาปกคลุมประเทศไทยตอนบนเป็นระยะ', 'โดยจะมีกำลังค่อนข้างแรงและต่อเนื่อง', 'ประกอบกับมรสุมตะวันออกเฉียงเหนือกำลังแรงยังคงพัดปกคลุมประเทศไทย', 'นอกจากนี้จะมีร่องมรสุมพาดผ่านบริเวณภาคใต้ตอนล่างในบางช่วง', 'สรุปเดือนนี้', 'คาดว่า', 'ปริมาณฝนรวมบริเวณประเทศไทยตอนบนจะสูงกว่าค่าปกติประมาณร้อยละ', 'ส่วนภาคใต้จะสูงกว่าค่าปกติร้อยละ', 'ส่าหรับอุณหภูมิเฉลี่ยจะสูงกว่าค่าปกติประมาณ', 'องศาเซลเซียส', 'สวัสดีค่ะ']\n"
     ]
    }
   ],
   "source": [
    "input_txt = open(\"corpus1.txt\",\"r\")\n",
    "text = input_txt.read()\n",
    "txt = clean_msg(text)\n",
    "corpus = txt.split()\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['พยากรณ์อากาศ'], ['ชั่วโมง', 'ข้าง', 'หน้า'], ['บริเวณ', 'ความ', 'กด', 'อากาศ', 'สูง', 'หรือ', 'มวล', 'อากาศ', 'เย็น', 'กำลัง', 'ปานกลาง', 'จาก', 'ประเทศ', 'จีน', 'แผ่', 'ปกคลุม', 'ประเทศ', 'ไทย', 'ตอน', 'บน'], ['ประกอบ', 'กับ', 'มี', 'หย่อม', 'ความ', 'กด', 'อากาศ', 'ต่ำ', 'ปกคลุม', 'บริเวณ', 'ประเทศ', 'กัมพูชา'], ['ลักษณะ', 'เช่น', 'นี้', 'ทำ', 'ให้', 'ประเทศ', 'ไทย', 'ตอน', 'บน', 'มี', 'ฝน', 'เกิด', 'ขึ้น'], ['กับ', 'มี', 'อากาศ', 'เย็น'], ['ส่วน', 'บริเวณ', 'ยอด', 'ดอย', 'และ', 'ยอดภู'], ['มี', 'อากาศ', 'หนาว'], ['สำหรับ', 'มรสุม', 'ตะวัน', 'ออก', 'เฉียง', 'เหนือ', 'พัด', 'ปกคลุม', 'อ่าวไทย', 'และ', 'ภาค', 'ใต้'], ['ทำ', 'ให้', 'ภาค', 'ใต้', 'มี', 'ฝน', 'ตก', 'ต่อเนื่อง'], ['อนึ่ง'], ['พายุ', 'โซนร้อน'], ['อัสนี'], ['พายุ', 'ระดับ'], ['บริเวณ', 'ตะวัน', 'ตก', 'เฉียง', 'ใต้', 'ของ', 'เกาะ', 'ไต้หวัน'], ['มี', 'แนวโน้ม', 'ที่', 'จะ', 'อ่อน', 'กำลัง', 'ลง'], ['และ', 'ไม่', 'มี', 'ผล', 'กระทบ', 'ต่อ', 'ประเทศ', 'ไทย'], ['ใน', 'ช่วง', 'วัน', 'ที่'], ['พย'], ['บริเวณ', 'ความ', 'กด', 'อากาศ', 'สูง', 'หรือ', 'มวล', 'อากาศ', 'เย็น', 'กำลัง', 'ปานกลาง', 'จาก', 'ประเทศ', 'จีน', 'ปกคลุม', 'ประเทศ', 'ไทย', 'ตอน', 'บน'], ['ประกอบ', 'กับ', 'มี', 'หย่อม', 'ความ', 'กด', 'อากาศ', 'ต่ำ', 'ปกคลุม', 'บริเวณ', 'ประเทศ', 'กัมพูชา'], ['ลักษณะ', 'เช่น', 'นี้', 'ทำ', 'ให้', 'บริเวณ', 'ประเทศ', 'ไทย', 'ตอน', 'บน', 'มี', 'อากาศ', 'เย็น', 'กับ', 'มี', 'ฝน', 'เล็กน้อย', 'ถึง', 'ปานกลาง'], ['โดย', 'เฉพาะ', 'บริเวณ', 'ภาค', 'ตะวัน', 'ออก', 'เฉียง', 'เหนือ', 'ตอน', 'ล่าง', 'และ', 'ภาค', 'ตะวัน', 'ออก'], ['สำหรับ', 'ภาค', 'ใต้', 'ตอน', 'ล่าง', 'มี', 'ฝน', 'ตก', 'หนัก', 'บาง', 'แห่ง'], ['เนื่อง', 'จาก', 'มรสุม', 'ตะวัน', 'ออก', 'เฉียง', 'เหนือ', 'พัด', 'ปกคลุม', 'อ่าวไทย', 'และ', 'ภาค', 'ใต้'], ['ส่วน', 'ใน', 'ช่วง', 'วัน', 'ที่'], ['พย'], ['บริเวณ', 'ความ', 'กด', 'อากาศ', 'สูง', 'หรือ', 'มวล', 'อากาศ', 'เย็น', 'กำลัง', 'ค่อนข้าง', 'แรง', 'อีก', 'ระลอก', 'จาก', 'ประเทศ', 'จีน', 'จะ', 'แผ่', 'เสริม', 'ลง', 'มา', 'ปกคลุม', 'ประเทศ', 'ไทย', 'ตอน', 'บน'], ['ทำ', 'ให้', 'ประเทศ', 'ไทย', 'ตอน', 'บน'], ['มี', 'อุณหภูมิ', 'ลด', 'ลง'], ['องศา', 'เซลเซียส'], ['กับ', 'มี', 'อากาศ', 'เย็น', 'และ', 'มี', 'ลม', 'แรง'], ['ใน', 'ขณะ', 'ที่', 'มรสุม', 'ตะวัน', 'ออก', 'เฉียง', 'เหนือ', 'ที่', 'พัด', 'ปกคลุม', 'อ่าวไทย', 'ตอน', 'บน', 'และ', 'ภาค', 'ใต้', 'จะ', 'มี', 'กำลัง', 'แรง', 'ขึ้น'], ['ทำ', 'ให้', 'ภาค', 'ใต้', 'ตอน', 'ล่าง', 'ยังคง', 'มี', 'ฝน', 'ตก', 'หนัก', 'บาง', 'แห่ง'], ['ส่วน', 'คลื่น', 'ลม', 'บริเวณ', 'อ่าวไทย', 'ตอน', 'บน', 'มี', 'กำลัง', 'ปานกลาง'], ['โดย', 'มี', 'คลื่น', 'สูง', 'ประมาณ'], ['เมตร'], ['บริเวณ', 'ที่', 'มี', 'ฝนฟ้า', 'คะนอง', 'คลื่น', 'สูง', 'มาก', 'กว่า'], ['เมตร'], ['อนึ่ง'], ['สำหรับ', 'พายุ', 'โซนร้อน'], ['อัสนี'], ['พายุ', 'ระดับ'], ['ทาง', 'เหนือ', 'ของ', 'ประเทศ', 'ฟิลิปปินส์', 'มี', 'แนวโน้ม', 'จะ', 'อ่อน', 'กำลัง', 'ลง', 'ใน', 'ช่วง', 'วัน', 'ที่'], ['พย'], ['โดย', 'พายุ', 'นี้', 'ไม่', 'มี', 'ผล', 'กระทบ', 'ต่อ', 'ประเทศ', 'ไทย'], ['ส่วน', 'ใน', 'ช่วง', 'วัน', 'ที่'], ['พย'], ['จะ', 'มี', 'หย่อม', 'ความ', 'กด', 'อากาศ', 'ต่ำ', 'กำลัง', 'แรง', 'เคลื่อน', 'ตัว', 'ผ่าน', 'บริเวณ', 'ประเทศ', 'เวียดนาม', 'ตอน', 'กลาง'], ['ขอ', 'ให้', 'ประชาชน', 'บริเวณ', 'ประเทศ', 'ไทย', 'ตอน', 'บน', 'ดูแล', 'สุขภาพ', 'เนื่อง', 'จาก', 'สภาพ', 'อากาศ', 'ที่', 'แปรปรวน', 'ไว้', 'ด้วย'], ['และ', 'ประชาชน', 'บริเวณ', 'ภาค', 'ใต้', 'ระวัง', 'อันตราย', 'จาก', 'ฝน', 'ที่', 'ตก', 'หนัก', 'และ', 'ฝน', 'ที่', 'ตก', 'สะสม', 'ไว้', 'ด้วย'], ['ใน', 'ช่วง', 'วัน', 'ที่'], ['พย'], ['ขอ', 'ให้', 'เกษตรกร', 'เตรียม', 'การ', 'ป้องกัน', 'และ', 'ระวัง', 'ความ', 'เสียหาย', 'ที่', 'จะ', 'เกิด', 'ต่อ', 'ผล', 'ผลิต', 'ทาง', 'การ', 'เกษตร', 'ไว้', 'ด้วย'], ['บริเวณ', 'ความ', 'กด', 'อากาศ', 'สูง', 'จาก', 'ประเทศ', 'จีน', 'ได้', 'แผ่', 'ลง', 'มา', 'ปกคลุม', 'ภาค', 'เหนือ', 'ตอน', 'บน', 'และ', 'ภาค', 'ตะวัน', 'ออก', 'เฉียง', 'เหนือ', 'ใน', 'ระยะ', 'ต้น', 'และ', 'กลาง', 'ช่วง', 'และ', 'แผ่', 'ปกคลุม', 'ประเทศ', 'ไทย', 'ตอน', 'บน', 'ใน', 'ระยะ', 'ปลาย', 'ช่วง'], ['ประกอบ', 'กับ', 'ใน', 'วัน', 'แรก', 'ของ', 'ช่วง', 'มี', 'หย่อม', 'ความ', 'กด', 'อากาศ', 'ต่ำ', 'ปกคลุม', 'อยู่', 'บริเวณ', 'ภาค', 'เหนือ', 'และ', 'ภาค', 'ตะวัน', 'ออก', 'เฉียง', 'เหนือ'], ['ลักษณะ', 'ดัง', 'กล่าว', 'ทำ', 'ให้', 'บริเวณ', 'ประเทศ', 'ไทย', 'ตอน', 'บน', 'มี', 'อากาศ', 'เย็น', 'เกือบ', 'ทั่วไป', 'ใน', 'ภาค', 'เหนือ', 'และ', 'ภาค', 'ตะวัน', 'ออก', 'เฉียง', 'เหนือ'], ['กับ', 'มี', 'ฝน', 'ส่วน', 'มาก', 'ใน', 'ระยะ', 'ต้น', 'ช่วง'], ['ส่วน', 'ภาค', 'ใต้', 'มี', 'ฝน', 'ตลอด', 'ช่วง', 'จาก', 'อิทธิพล', 'ของ', 'มรสุม', 'ตะวัน', 'ออก', 'เฉียง', 'เหนือ', 'ที่', 'พัด', 'ปกคลุม', 'อ่าวไทย', 'และ', 'ภาค', 'ใต้', 'เกือบ', 'ตลอด', 'ช่วง'], ['ประกอบ', 'กับ', 'มี', 'ร่องมรสุม', 'พาดผ่าน', 'ภาค', 'ใต้', 'ตอน', 'กลาง', 'ใน', 'ระยะ', 'ครึ่ง', 'แรก', 'ของ', 'ช่วง'], ['จาก', 'นั้น', 'ได้', 'เลื่อน', 'ลง', 'ไป', 'พาด', 'ผ่าน', 'บริเวณ', 'ภาค', 'ใต้', 'ตอน', 'ล่าง'], ['บริเวณ', 'ประเทศ', 'ไทย', 'ตอน', 'บน'], ['จะ', 'มี', 'อากาศ', 'หนาวเย็น', 'มาก', 'ขึ้น'], ['โดย', 'เฉพาะ', 'ใน', 'ระยะ', 'ครึ่ง', 'หลัง', 'ของ', 'เดือน'], ['กับ', 'จะ', 'มี', 'หมอก', 'หนา', 'หลาย', 'พื้นที่', 'ใน', 'บาง', 'ช่วง'], ['บริเวณ', 'เทือกเขา'], ['ยอด', 'ดอย', 'และ', 'ยอด', 'ภู', 'จะ', 'มี', 'อากาศ', 'หนาว', 'ถึง', 'หนาว', 'จัด', 'กับ', 'มี', 'น้ำ', 'ค้าง', 'แข็ง', 'เกิด', 'ขึ้น', 'ได้', 'ใน', 'บาง', 'วัน'], ['สำหรับ', 'ภาค', 'ใต้', 'ฝั่ง', 'ตะวัน', 'ออก', 'ยังคง', 'มี', 'ฝน', 'ตก', 'ชุก', 'หนาแน่น'], ['กับ', 'จะ', 'มี', 'ฝน', 'ตก', 'หนัก', 'บาง', 'แห่ง', 'ใน', 'บาง', 'วัน'], ['โดย', 'เฉพาะ', 'ตั้งแต่', 'จังหวัดสุราษฎร์ธานี', 'ลง', 'ไป'], ['คลื่น', 'ลม', 'ใน', 'ทะเล', 'อ่าวไทย', 'ยังคง', 'มี', 'กำลัง', 'แรง'], ['จะ', 'มี', 'คลื่น', 'สูง'], ['เมตร', 'ใน', 'บาง', 'ช่วง'], ['ส่วน', 'ภาค', 'ใต้', 'ฝั่ง', 'ตะวัน', 'ตก', 'ฝน', 'จะ', 'ลด', 'ลง'], ['คลื่น', 'ลม', 'ทะเล', 'อันดามัน', 'จะ', 'มี', 'คลื่น', 'สูง'], ['เมตร'], ['เนื่อง', 'จาก'], ['บริเวณ', 'ความ', 'กด', 'อากาศ', 'สูง', 'จาก', 'ประเทศ', 'จีน', 'ยังคง', 'แผ่', 'เสริม', 'ลง', 'มา', 'ปกคลุม', 'ประเทศ', 'ไทย', 'ตอน', 'บน', 'เป็น', 'ระยะ'], ['โดย', 'จะ', 'มี', 'กำลัง', 'ค่อนข้าง', 'แรง', 'และ', 'ต่อเนื่อง'], ['ประกอบ', 'กับ', 'มรสุม', 'ตะวัน', 'ออก', 'เฉียง', 'เหนือ', 'กำลัง', 'แรง', 'ยังคง', 'พัด', 'ปกคลุม', 'ประเทศ', 'ไทย'], ['นอก', 'จาก', 'นี้', 'จะ', 'มี', 'ร่องมรสุม', 'พาด', 'ผ่าน', 'บริเวณ', 'ภาค', 'ใต้', 'ตอน', 'ล่าง', 'ใน', 'บาง', 'ช่วง'], ['สรุป', 'เดือน', 'นี้'], ['คาด', 'ว่า'], ['ปริมาณ', 'ฝน', 'รวม', 'บริเวณ', 'ประเทศ', 'ไทย', 'ตอน', 'บน', 'จะ', 'สูง', 'กว่า', 'ค่า', 'ปกติ', 'ประมาณ', 'ร้อยละ'], ['ส่วน', 'ภาค', 'ใต้', 'จะ', 'สูง', 'กว่า', 'ค่า', 'ปกติ', 'ร้อย', 'ละ'], ['ส่า', 'หรับ', 'อุณหภูมิ', 'เฉลี่ย', 'จะ', 'สูง', 'กว่า', 'ค่า', 'ปกติ', 'ประมาณ'], ['องศา', 'เซลเซียส'], ['สวัสดี', 'ค่ะ']]\n"
     ]
    }
   ],
   "source": [
    "def word_tokenize(corpus):\n",
    "    x = 0\n",
    "    words = []\n",
    "    for i in corpus:\n",
    "        list_word = deepcut.tokenize(i,custom_dict='custom_dict.txt') #ตัดคำ\n",
    "        words.append(list_word)\n",
    "        x += 1\n",
    "    return words\n",
    "# corpus=word_tokenize(corpus)\n",
    "# x_test = word_tokenize(x_test)\n",
    "words = word_tokenize(corpus)\n",
    "print(words)\n",
    "# print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 1\n",
    "def generate_data(corpus, window_size = 2):\n",
    "    maxlen = window_size*2\n",
    "    contexts = []\n",
    "    labels   = []   \n",
    "    for words in corpus:\n",
    "        L = len(words)\n",
    "        if len(words) < 2:\n",
    "            contexts.append([''])\n",
    "            labels.append(words[0])\n",
    "        else:\n",
    "            for index, word in enumerate(words):\n",
    "\n",
    "                s = index - window_size\n",
    "                e = index + window_size + 1\n",
    "\n",
    "                contexts.append([words[i] for i in range(s, e) if 0 <= i < L and i != index])\n",
    "                labels.append(word)\n",
    "\n",
    "    return contexts,labels\n",
    "    #ฟังก์ชั้นสำหรับแบ่งข้อมูลให้อยู่ในรูป target and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, ytrain = generate_data(words, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[''], ['ข้าง'], ['ชั่วโมง', 'หน้า'], ['ข้าง'], ['ความ'], ['บริเวณ', 'กด'], ['ความ', 'อากาศ'], ['กด', 'สูง'], ['อากาศ', 'หรือ'], ['สูง', 'มวล'], ['หรือ', 'อากาศ'], ['มวล', 'เย็น'], ['อากาศ', 'กำลัง'], ['เย็น', 'ปานกลาง'], ['กำลัง', 'จาก'], ['ปานกลาง', 'ประเทศ'], ['จาก', 'จีน'], ['ประเทศ', 'แผ่'], ['จีน', 'ปกคลุม'], ['แผ่', 'ประเทศ'], ['ปกคลุม', 'ไทย'], ['ประเทศ', 'ตอน'], ['ไทย', 'บน'], ['ตอน'], ['กับ'], ['ประกอบ', 'มี'], ['กับ', 'หย่อม'], ['มี', 'ความ'], ['หย่อม', 'กด'], ['ความ', 'อากาศ'], ['กด', 'ต่ำ'], ['อากาศ', 'ปกคลุม'], ['ต่ำ', 'บริเวณ'], ['ปกคลุม', 'ประเทศ'], ['บริเวณ', 'กัมพูชา'], ['ประเทศ'], ['เช่น'], ['ลักษณะ', 'นี้'], ['เช่น', 'ทำ'], ['นี้', 'ให้'], ['ทำ', 'ประเทศ'], ['ให้', 'ไทย'], ['ประเทศ', 'ตอน'], ['ไทย', 'บน'], ['ตอน', 'มี'], ['บน', 'ฝน'], ['มี', 'เกิด'], ['ฝน', 'ขึ้น'], ['เกิด'], ['มี'], ['กับ', 'อากาศ'], ['มี', 'เย็น'], ['อากาศ'], ['บริเวณ'], ['ส่วน', 'ยอด'], ['บริเวณ', 'ดอย'], ['ยอด', 'และ'], ['ดอย', 'ยอดภู'], ['และ'], ['อากาศ'], ['มี', 'หนาว'], ['อากาศ'], ['มรสุม'], ['สำหรับ', 'ตะวัน'], ['มรสุม', 'ออก'], ['ตะวัน', 'เฉียง'], ['ออก', 'เหนือ'], ['เฉียง', 'พัด'], ['เหนือ', 'ปกคลุม'], ['พัด', 'อ่าวไทย'], ['ปกคลุม', 'และ'], ['อ่าวไทย', 'ภาค'], ['และ', 'ใต้'], ['ภาค'], ['ให้'], ['ทำ', 'ภาค'], ['ให้', 'ใต้'], ['ภาค', 'มี'], ['ใต้', 'ฝน'], ['มี', 'ตก'], ['ฝน', 'ต่อเนื่อง'], ['ตก'], [''], ['โซนร้อน'], ['พายุ'], [''], ['ระดับ'], ['พายุ'], ['ตะวัน'], ['บริเวณ', 'ตก'], ['ตะวัน', 'เฉียง'], ['ตก', 'ใต้'], ['เฉียง', 'ของ'], ['ใต้', 'เกาะ'], ['ของ', 'ไต้หวัน'], ['เกาะ'], ['แนวโน้ม'], ['มี', 'ที่'], ['แนวโน้ม', 'จะ'], ['ที่', 'อ่อน'], ['จะ', 'กำลัง'], ['อ่อน', 'ลง'], ['กำลัง'], ['ไม่'], ['และ', 'มี'], ['ไม่', 'ผล'], ['มี', 'กระทบ'], ['ผล', 'ต่อ'], ['กระทบ', 'ประเทศ'], ['ต่อ', 'ไทย'], ['ประเทศ'], ['ช่วง'], ['ใน', 'วัน'], ['ช่วง', 'ที่'], ['วัน'], [''], ['ความ'], ['บริเวณ', 'กด'], ['ความ', 'อากาศ'], ['กด', 'สูง'], ['อากาศ', 'หรือ'], ['สูง', 'มวล'], ['หรือ', 'อากาศ'], ['มวล', 'เย็น'], ['อากาศ', 'กำลัง'], ['เย็น', 'ปานกลาง'], ['กำลัง', 'จาก'], ['ปานกลาง', 'ประเทศ'], ['จาก', 'จีน'], ['ประเทศ', 'ปกคลุม'], ['จีน', 'ประเทศ'], ['ปกคลุม', 'ไทย'], ['ประเทศ', 'ตอน'], ['ไทย', 'บน'], ['ตอน'], ['กับ'], ['ประกอบ', 'มี'], ['กับ', 'หย่อม'], ['มี', 'ความ'], ['หย่อม', 'กด'], ['ความ', 'อากาศ'], ['กด', 'ต่ำ'], ['อากาศ', 'ปกคลุม'], ['ต่ำ', 'บริเวณ'], ['ปกคลุม', 'ประเทศ'], ['บริเวณ', 'กัมพูชา'], ['ประเทศ'], ['เช่น'], ['ลักษณะ', 'นี้'], ['เช่น', 'ทำ'], ['นี้', 'ให้'], ['ทำ', 'บริเวณ'], ['ให้', 'ประเทศ'], ['บริเวณ', 'ไทย'], ['ประเทศ', 'ตอน'], ['ไทย', 'บน'], ['ตอน', 'มี'], ['บน', 'อากาศ'], ['มี', 'เย็น'], ['อากาศ', 'กับ'], ['เย็น', 'มี'], ['กับ', 'ฝน'], ['มี', 'เล็กน้อย'], ['ฝน', 'ถึง'], ['เล็กน้อย', 'ปานกลาง'], ['ถึง'], ['เฉพาะ'], ['โดย', 'บริเวณ'], ['เฉพาะ', 'ภาค'], ['บริเวณ', 'ตะวัน'], ['ภาค', 'ออก'], ['ตะวัน', 'เฉียง'], ['ออก', 'เหนือ'], ['เฉียง', 'ตอน'], ['เหนือ', 'ล่าง'], ['ตอน', 'และ'], ['ล่าง', 'ภาค'], ['และ', 'ตะวัน'], ['ภาค', 'ออก'], ['ตะวัน'], ['ภาค'], ['สำหรับ', 'ใต้'], ['ภาค', 'ตอน'], ['ใต้', 'ล่าง'], ['ตอน', 'มี'], ['ล่าง', 'ฝน'], ['มี', 'ตก'], ['ฝน', 'หนัก'], ['ตก', 'บาง'], ['หนัก', 'แห่ง'], ['บาง'], ['จาก'], ['เนื่อง', 'มรสุม'], ['จาก', 'ตะวัน'], ['มรสุม', 'ออก'], ['ตะวัน', 'เฉียง'], ['ออก', 'เหนือ'], ['เฉียง', 'พัด'], ['เหนือ', 'ปกคลุม'], ['พัด', 'อ่าวไทย'], ['ปกคลุม', 'และ'], ['อ่าวไทย', 'ภาค'], ['และ', 'ใต้'], ['ภาค'], ['ใน'], ['ส่วน', 'ช่วง'], ['ใน', 'วัน'], ['ช่วง', 'ที่'], ['วัน'], [''], ['ความ'], ['บริเวณ', 'กด'], ['ความ', 'อากาศ'], ['กด', 'สูง'], ['อากาศ', 'หรือ'], ['สูง', 'มวล'], ['หรือ', 'อากาศ'], ['มวล', 'เย็น'], ['อากาศ', 'กำลัง'], ['เย็น', 'ค่อนข้าง'], ['กำลัง', 'แรง'], ['ค่อนข้าง', 'อีก'], ['แรง', 'ระลอก'], ['อีก', 'จาก'], ['ระลอก', 'ประเทศ'], ['จาก', 'จีน'], ['ประเทศ', 'จะ'], ['จีน', 'แผ่'], ['จะ', 'เสริม'], ['แผ่', 'ลง'], ['เสริม', 'มา'], ['ลง', 'ปกคลุม'], ['มา', 'ประเทศ'], ['ปกคลุม', 'ไทย'], ['ประเทศ', 'ตอน'], ['ไทย', 'บน'], ['ตอน'], ['ให้'], ['ทำ', 'ประเทศ'], ['ให้', 'ไทย'], ['ประเทศ', 'ตอน'], ['ไทย', 'บน'], ['ตอน'], ['อุณหภูมิ'], ['มี', 'ลด'], ['อุณหภูมิ', 'ลง'], ['ลด'], ['เซลเซียส'], ['องศา'], ['มี'], ['กับ', 'อากาศ'], ['มี', 'เย็น'], ['อากาศ', 'และ'], ['เย็น', 'มี'], ['และ', 'ลม'], ['มี', 'แรง'], ['ลม'], ['ขณะ'], ['ใน', 'ที่'], ['ขณะ', 'มรสุม'], ['ที่', 'ตะวัน'], ['มรสุม', 'ออก'], ['ตะวัน', 'เฉียง'], ['ออก', 'เหนือ'], ['เฉียง', 'ที่'], ['เหนือ', 'พัด'], ['ที่', 'ปกคลุม'], ['พัด', 'อ่าวไทย'], ['ปกคลุม', 'ตอน'], ['อ่าวไทย', 'บน'], ['ตอน', 'และ'], ['บน', 'ภาค'], ['และ', 'ใต้'], ['ภาค', 'จะ'], ['ใต้', 'มี'], ['จะ', 'กำลัง'], ['มี', 'แรง'], ['กำลัง', 'ขึ้น'], ['แรง'], ['ให้'], ['ทำ', 'ภาค'], ['ให้', 'ใต้'], ['ภาค', 'ตอน'], ['ใต้', 'ล่าง'], ['ตอน', 'ยังคง'], ['ล่าง', 'มี'], ['ยังคง', 'ฝน'], ['มี', 'ตก'], ['ฝน', 'หนัก'], ['ตก', 'บาง'], ['หนัก', 'แห่ง'], ['บาง'], ['คลื่น'], ['ส่วน', 'ลม'], ['คลื่น', 'บริเวณ'], ['ลม', 'อ่าวไทย'], ['บริเวณ', 'ตอน'], ['อ่าวไทย', 'บน'], ['ตอน', 'มี'], ['บน', 'กำลัง'], ['มี', 'ปานกลาง'], ['กำลัง'], ['มี'], ['โดย', 'คลื่น'], ['มี', 'สูง'], ['คลื่น', 'ประมาณ'], ['สูง'], [''], ['ที่'], ['บริเวณ', 'มี'], ['ที่', 'ฝนฟ้า'], ['มี', 'คะนอง'], ['ฝนฟ้า', 'คลื่น'], ['คะนอง', 'สูง'], ['คลื่น', 'มาก'], ['สูง', 'กว่า'], ['มาก'], [''], [''], ['พายุ'], ['สำหรับ', 'โซนร้อน'], ['พายุ'], [''], ['ระดับ'], ['พายุ'], ['เหนือ'], ['ทาง', 'ของ'], ['เหนือ', 'ประเทศ'], ['ของ', 'ฟิลิปปินส์'], ['ประเทศ', 'มี'], ['ฟิลิปปินส์', 'แนวโน้ม'], ['มี', 'จะ'], ['แนวโน้ม', 'อ่อน'], ['จะ', 'กำลัง'], ['อ่อน', 'ลง'], ['กำลัง', 'ใน'], ['ลง', 'ช่วง'], ['ใน', 'วัน'], ['ช่วง', 'ที่'], ['วัน'], [''], ['พายุ'], ['โดย', 'นี้'], ['พายุ', 'ไม่'], ['นี้', 'มี'], ['ไม่', 'ผล'], ['มี', 'กระทบ'], ['ผล', 'ต่อ'], ['กระทบ', 'ประเทศ'], ['ต่อ', 'ไทย'], ['ประเทศ'], ['ใน'], ['ส่วน', 'ช่วง'], ['ใน', 'วัน'], ['ช่วง', 'ที่'], ['วัน'], [''], ['มี'], ['จะ', 'หย่อม'], ['มี', 'ความ'], ['หย่อม', 'กด'], ['ความ', 'อากาศ'], ['กด', 'ต่ำ'], ['อากาศ', 'กำลัง'], ['ต่ำ', 'แรง'], ['กำลัง', 'เคลื่อน'], ['แรง', 'ตัว'], ['เคลื่อน', 'ผ่าน'], ['ตัว', 'บริเวณ'], ['ผ่าน', 'ประเทศ'], ['บริเวณ', 'เวียดนาม'], ['ประเทศ', 'ตอน'], ['เวียดนาม', 'กลาง'], ['ตอน'], ['ให้'], ['ขอ', 'ประชาชน'], ['ให้', 'บริเวณ'], ['ประชาชน', 'ประเทศ'], ['บริเวณ', 'ไทย'], ['ประเทศ', 'ตอน'], ['ไทย', 'บน'], ['ตอน', 'ดูแล'], ['บน', 'สุขภาพ'], ['ดูแล', 'เนื่อง'], ['สุขภาพ', 'จาก'], ['เนื่อง', 'สภาพ'], ['จาก', 'อากาศ'], ['สภาพ', 'ที่'], ['อากาศ', 'แปรปรวน'], ['ที่', 'ไว้'], ['แปรปรวน', 'ด้วย'], ['ไว้'], ['ประชาชน'], ['และ', 'บริเวณ'], ['ประชาชน', 'ภาค'], ['บริเวณ', 'ใต้'], ['ภาค', 'ระวัง'], ['ใต้', 'อันตราย'], ['ระวัง', 'จาก'], ['อันตราย', 'ฝน'], ['จาก', 'ที่'], ['ฝน', 'ตก'], ['ที่', 'หนัก'], ['ตก', 'และ'], ['หนัก', 'ฝน'], ['และ', 'ที่'], ['ฝน', 'ตก'], ['ที่', 'สะสม'], ['ตก', 'ไว้'], ['สะสม', 'ด้วย'], ['ไว้'], ['ช่วง'], ['ใน', 'วัน'], ['ช่วง', 'ที่'], ['วัน'], [''], ['ให้'], ['ขอ', 'เกษตรกร'], ['ให้', 'เตรียม'], ['เกษตรกร', 'การ'], ['เตรียม', 'ป้องกัน'], ['การ', 'และ'], ['ป้องกัน', 'ระวัง'], ['และ', 'ความ'], ['ระวัง', 'เสียหาย'], ['ความ', 'ที่'], ['เสียหาย', 'จะ'], ['ที่', 'เกิด'], ['จะ', 'ต่อ'], ['เกิด', 'ผล'], ['ต่อ', 'ผลิต'], ['ผล', 'ทาง'], ['ผลิต', 'การ'], ['ทาง', 'เกษตร'], ['การ', 'ไว้'], ['เกษตร', 'ด้วย'], ['ไว้'], ['ความ'], ['บริเวณ', 'กด'], ['ความ', 'อากาศ'], ['กด', 'สูง'], ['อากาศ', 'จาก'], ['สูง', 'ประเทศ'], ['จาก', 'จีน'], ['ประเทศ', 'ได้'], ['จีน', 'แผ่'], ['ได้', 'ลง'], ['แผ่', 'มา'], ['ลง', 'ปกคลุม'], ['มา', 'ภาค'], ['ปกคลุม', 'เหนือ'], ['ภาค', 'ตอน'], ['เหนือ', 'บน'], ['ตอน', 'และ'], ['บน', 'ภาค'], ['และ', 'ตะวัน'], ['ภาค', 'ออก'], ['ตะวัน', 'เฉียง'], ['ออก', 'เหนือ'], ['เฉียง', 'ใน'], ['เหนือ', 'ระยะ'], ['ใน', 'ต้น'], ['ระยะ', 'และ'], ['ต้น', 'กลาง'], ['และ', 'ช่วง'], ['กลาง', 'และ'], ['ช่วง', 'แผ่'], ['และ', 'ปกคลุม'], ['แผ่', 'ประเทศ'], ['ปกคลุม', 'ไทย'], ['ประเทศ', 'ตอน'], ['ไทย', 'บน'], ['ตอน', 'ใน'], ['บน', 'ระยะ'], ['ใน', 'ปลาย'], ['ระยะ', 'ช่วง'], ['ปลาย'], ['กับ'], ['ประกอบ', 'ใน'], ['กับ', 'วัน'], ['ใน', 'แรก'], ['วัน', 'ของ'], ['แรก', 'ช่วง'], ['ของ', 'มี'], ['ช่วง', 'หย่อม'], ['มี', 'ความ'], ['หย่อม', 'กด'], ['ความ', 'อากาศ'], ['กด', 'ต่ำ'], ['อากาศ', 'ปกคลุม'], ['ต่ำ', 'อยู่'], ['ปกคลุม', 'บริเวณ'], ['อยู่', 'ภาค'], ['บริเวณ', 'เหนือ'], ['ภาค', 'และ'], ['เหนือ', 'ภาค'], ['และ', 'ตะวัน'], ['ภาค', 'ออก'], ['ตะวัน', 'เฉียง'], ['ออก', 'เหนือ'], ['เฉียง'], ['ดัง'], ['ลักษณะ', 'กล่าว'], ['ดัง', 'ทำ'], ['กล่าว', 'ให้'], ['ทำ', 'บริเวณ'], ['ให้', 'ประเทศ'], ['บริเวณ', 'ไทย'], ['ประเทศ', 'ตอน'], ['ไทย', 'บน'], ['ตอน', 'มี'], ['บน', 'อากาศ'], ['มี', 'เย็น'], ['อากาศ', 'เกือบ'], ['เย็น', 'ทั่วไป'], ['เกือบ', 'ใน'], ['ทั่วไป', 'ภาค'], ['ใน', 'เหนือ'], ['ภาค', 'และ'], ['เหนือ', 'ภาค'], ['และ', 'ตะวัน'], ['ภาค', 'ออก'], ['ตะวัน', 'เฉียง'], ['ออก', 'เหนือ'], ['เฉียง'], ['มี'], ['กับ', 'ฝน'], ['มี', 'ส่วน'], ['ฝน', 'มาก'], ['ส่วน', 'ใน'], ['มาก', 'ระยะ'], ['ใน', 'ต้น'], ['ระยะ', 'ช่วง'], ['ต้น'], ['ภาค'], ['ส่วน', 'ใต้'], ['ภาค', 'มี'], ['ใต้', 'ฝน'], ['มี', 'ตลอด'], ['ฝน', 'ช่วง'], ['ตลอด', 'จาก'], ['ช่วง', 'อิทธิพล'], ['จาก', 'ของ'], ['อิทธิพล', 'มรสุม'], ['ของ', 'ตะวัน'], ['มรสุม', 'ออก'], ['ตะวัน', 'เฉียง'], ['ออก', 'เหนือ'], ['เฉียง', 'ที่'], ['เหนือ', 'พัด'], ['ที่', 'ปกคลุม'], ['พัด', 'อ่าวไทย'], ['ปกคลุม', 'และ'], ['อ่าวไทย', 'ภาค'], ['และ', 'ใต้'], ['ภาค', 'เกือบ'], ['ใต้', 'ตลอด'], ['เกือบ', 'ช่วง'], ['ตลอด'], ['กับ'], ['ประกอบ', 'มี'], ['กับ', 'ร่องมรสุม'], ['มี', 'พาดผ่าน'], ['ร่องมรสุม', 'ภาค'], ['พาดผ่าน', 'ใต้'], ['ภาค', 'ตอน'], ['ใต้', 'กลาง'], ['ตอน', 'ใน'], ['กลาง', 'ระยะ'], ['ใน', 'ครึ่ง'], ['ระยะ', 'แรก'], ['ครึ่ง', 'ของ'], ['แรก', 'ช่วง'], ['ของ'], ['นั้น'], ['จาก', 'ได้'], ['นั้น', 'เลื่อน'], ['ได้', 'ลง'], ['เลื่อน', 'ไป'], ['ลง', 'พาด'], ['ไป', 'ผ่าน'], ['พาด', 'บริเวณ'], ['ผ่าน', 'ภาค'], ['บริเวณ', 'ใต้'], ['ภาค', 'ตอน'], ['ใต้', 'ล่าง'], ['ตอน'], ['ประเทศ'], ['บริเวณ', 'ไทย'], ['ประเทศ', 'ตอน'], ['ไทย', 'บน'], ['ตอน'], ['มี'], ['จะ', 'อากาศ'], ['มี', 'หนาวเย็น'], ['อากาศ', 'มาก'], ['หนาวเย็น', 'ขึ้น'], ['มาก'], ['เฉพาะ'], ['โดย', 'ใน'], ['เฉพาะ', 'ระยะ'], ['ใน', 'ครึ่ง'], ['ระยะ', 'หลัง'], ['ครึ่ง', 'ของ'], ['หลัง', 'เดือน'], ['ของ'], ['จะ'], ['กับ', 'มี'], ['จะ', 'หมอก'], ['มี', 'หนา'], ['หมอก', 'หลาย'], ['หนา', 'พื้นที่'], ['หลาย', 'ใน'], ['พื้นที่', 'บาง'], ['ใน', 'ช่วง'], ['บาง'], ['เทือกเขา'], ['บริเวณ'], ['ดอย'], ['ยอด', 'และ'], ['ดอย', 'ยอด'], ['และ', 'ภู'], ['ยอด', 'จะ'], ['ภู', 'มี'], ['จะ', 'อากาศ'], ['มี', 'หนาว'], ['อากาศ', 'ถึง'], ['หนาว', 'หนาว'], ['ถึง', 'จัด'], ['หนาว', 'กับ'], ['จัด', 'มี'], ['กับ', 'น้ำ'], ['มี', 'ค้าง'], ['น้ำ', 'แข็ง'], ['ค้าง', 'เกิด'], ['แข็ง', 'ขึ้น'], ['เกิด', 'ได้'], ['ขึ้น', 'ใน'], ['ได้', 'บาง'], ['ใน', 'วัน'], ['บาง'], ['ภาค'], ['สำหรับ', 'ใต้'], ['ภาค', 'ฝั่ง'], ['ใต้', 'ตะวัน'], ['ฝั่ง', 'ออก'], ['ตะวัน', 'ยังคง'], ['ออก', 'มี'], ['ยังคง', 'ฝน'], ['มี', 'ตก'], ['ฝน', 'ชุก'], ['ตก', 'หนาแน่น'], ['ชุก'], ['จะ'], ['กับ', 'มี'], ['จะ', 'ฝน'], ['มี', 'ตก'], ['ฝน', 'หนัก'], ['ตก', 'บาง'], ['หนัก', 'แห่ง'], ['บาง', 'ใน'], ['แห่ง', 'บาง'], ['ใน', 'วัน'], ['บาง'], ['เฉพาะ'], ['โดย', 'ตั้งแต่'], ['เฉพาะ', 'จังหวัดสุราษฎร์ธานี'], ['ตั้งแต่', 'ลง'], ['จังหวัดสุราษฎร์ธานี', 'ไป'], ['ลง'], ['ลม'], ['คลื่น', 'ใน'], ['ลม', 'ทะเล'], ['ใน', 'อ่าวไทย'], ['ทะเล', 'ยังคง'], ['อ่าวไทย', 'มี'], ['ยังคง', 'กำลัง'], ['มี', 'แรง'], ['กำลัง'], ['มี'], ['จะ', 'คลื่น'], ['มี', 'สูง'], ['คลื่น'], ['ใน'], ['เมตร', 'บาง'], ['ใน', 'ช่วง'], ['บาง'], ['ภาค'], ['ส่วน', 'ใต้'], ['ภาค', 'ฝั่ง'], ['ใต้', 'ตะวัน'], ['ฝั่ง', 'ตก'], ['ตะวัน', 'ฝน'], ['ตก', 'จะ'], ['ฝน', 'ลด'], ['จะ', 'ลง'], ['ลด'], ['ลม'], ['คลื่น', 'ทะเล'], ['ลม', 'อันดามัน'], ['ทะเล', 'จะ'], ['อันดามัน', 'มี'], ['จะ', 'คลื่น'], ['มี', 'สูง'], ['คลื่น'], [''], ['จาก'], ['เนื่อง'], ['ความ'], ['บริเวณ', 'กด'], ['ความ', 'อากาศ'], ['กด', 'สูง'], ['อากาศ', 'จาก'], ['สูง', 'ประเทศ'], ['จาก', 'จีน'], ['ประเทศ', 'ยังคง'], ['จีน', 'แผ่'], ['ยังคง', 'เสริม'], ['แผ่', 'ลง'], ['เสริม', 'มา'], ['ลง', 'ปกคลุม'], ['มา', 'ประเทศ'], ['ปกคลุม', 'ไทย'], ['ประเทศ', 'ตอน'], ['ไทย', 'บน'], ['ตอน', 'เป็น'], ['บน', 'ระยะ'], ['เป็น'], ['จะ'], ['โดย', 'มี'], ['จะ', 'กำลัง'], ['มี', 'ค่อนข้าง'], ['กำลัง', 'แรง'], ['ค่อนข้าง', 'และ'], ['แรง', 'ต่อเนื่อง'], ['และ'], ['กับ'], ['ประกอบ', 'มรสุม'], ['กับ', 'ตะวัน'], ['มรสุม', 'ออก'], ['ตะวัน', 'เฉียง'], ['ออก', 'เหนือ'], ['เฉียง', 'กำลัง'], ['เหนือ', 'แรง'], ['กำลัง', 'ยังคง'], ['แรง', 'พัด'], ['ยังคง', 'ปกคลุม'], ['พัด', 'ประเทศ'], ['ปกคลุม', 'ไทย'], ['ประเทศ'], ['จาก'], ['นอก', 'นี้'], ['จาก', 'จะ'], ['นี้', 'มี'], ['จะ', 'ร่องมรสุม'], ['มี', 'พาด'], ['ร่องมรสุม', 'ผ่าน'], ['พาด', 'บริเวณ'], ['ผ่าน', 'ภาค'], ['บริเวณ', 'ใต้'], ['ภาค', 'ตอน'], ['ใต้', 'ล่าง'], ['ตอน', 'ใน'], ['ล่าง', 'บาง'], ['ใน', 'ช่วง'], ['บาง'], ['เดือน'], ['สรุป', 'นี้'], ['เดือน'], ['ว่า'], ['คาด'], ['ฝน'], ['ปริมาณ', 'รวม'], ['ฝน', 'บริเวณ'], ['รวม', 'ประเทศ'], ['บริเวณ', 'ไทย'], ['ประเทศ', 'ตอน'], ['ไทย', 'บน'], ['ตอน', 'จะ'], ['บน', 'สูง'], ['จะ', 'กว่า'], ['สูง', 'ค่า'], ['กว่า', 'ปกติ'], ['ค่า', 'ประมาณ'], ['ปกติ', 'ร้อยละ'], ['ประมาณ'], ['ภาค'], ['ส่วน', 'ใต้'], ['ภาค', 'จะ'], ['ใต้', 'สูง'], ['จะ', 'กว่า'], ['สูง', 'ค่า'], ['กว่า', 'ปกติ'], ['ค่า', 'ร้อย'], ['ปกติ', 'ละ'], ['ร้อย'], ['หรับ'], ['ส่า', 'อุณหภูมิ'], ['หรับ', 'เฉลี่ย'], ['อุณหภูมิ', 'จะ'], ['เฉลี่ย', 'สูง'], ['จะ', 'กว่า'], ['สูง', 'ค่า'], ['กว่า', 'ปกติ'], ['ค่า', 'ประมาณ'], ['ปกติ'], ['เซลเซียส'], ['องศา'], ['ค่ะ'], ['สวัสดี']]\n",
      "810\n"
     ]
    }
   ],
   "source": [
    "print(xtrain)\n",
    "print(len(xtrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['พยากรณ์อากาศ', 'ชั่วโมง', 'ข้าง', 'หน้า', 'บริเวณ', 'ความ', 'กด', 'อากาศ', 'สูง', 'หรือ', 'มวล', 'อากาศ', 'เย็น', 'กำลัง', 'ปานกลาง', 'จาก', 'ประเทศ', 'จีน', 'แผ่', 'ปกคลุม', 'ประเทศ', 'ไทย', 'ตอน', 'บน', 'ประกอบ', 'กับ', 'มี', 'หย่อม', 'ความ', 'กด', 'อากาศ', 'ต่ำ', 'ปกคลุม', 'บริเวณ', 'ประเทศ', 'กัมพูชา', 'ลักษณะ', 'เช่น', 'นี้', 'ทำ', 'ให้', 'ประเทศ', 'ไทย', 'ตอน', 'บน', 'มี', 'ฝน', 'เกิด', 'ขึ้น', 'กับ', 'มี', 'อากาศ', 'เย็น', 'ส่วน', 'บริเวณ', 'ยอด', 'ดอย', 'และ', 'ยอดภู', 'มี', 'อากาศ', 'หนาว', 'สำหรับ', 'มรสุม', 'ตะวัน', 'ออก', 'เฉียง', 'เหนือ', 'พัด', 'ปกคลุม', 'อ่าวไทย', 'และ', 'ภาค', 'ใต้', 'ทำ', 'ให้', 'ภาค', 'ใต้', 'มี', 'ฝน', 'ตก', 'ต่อเนื่อง', 'อนึ่ง', 'พายุ', 'โซนร้อน', 'อัสนี', 'พายุ', 'ระดับ', 'บริเวณ', 'ตะวัน', 'ตก', 'เฉียง', 'ใต้', 'ของ', 'เกาะ', 'ไต้หวัน', 'มี', 'แนวโน้ม', 'ที่', 'จะ', 'อ่อน', 'กำลัง', 'ลง', 'และ', 'ไม่', 'มี', 'ผล', 'กระทบ', 'ต่อ', 'ประเทศ', 'ไทย', 'ใน', 'ช่วง', 'วัน', 'ที่', 'พย', 'บริเวณ', 'ความ', 'กด', 'อากาศ', 'สูง', 'หรือ', 'มวล', 'อากาศ', 'เย็น', 'กำลัง', 'ปานกลาง', 'จาก', 'ประเทศ', 'จีน', 'ปกคลุม', 'ประเทศ', 'ไทย', 'ตอน', 'บน', 'ประกอบ', 'กับ', 'มี', 'หย่อม', 'ความ', 'กด', 'อากาศ', 'ต่ำ', 'ปกคลุม', 'บริเวณ', 'ประเทศ', 'กัมพูชา', 'ลักษณะ', 'เช่น', 'นี้', 'ทำ', 'ให้', 'บริเวณ', 'ประเทศ', 'ไทย', 'ตอน', 'บน', 'มี', 'อากาศ', 'เย็น', 'กับ', 'มี', 'ฝน', 'เล็กน้อย', 'ถึง', 'ปานกลาง', 'โดย', 'เฉพาะ', 'บริเวณ', 'ภาค', 'ตะวัน', 'ออก', 'เฉียง', 'เหนือ', 'ตอน', 'ล่าง', 'และ', 'ภาค', 'ตะวัน', 'ออก', 'สำหรับ', 'ภาค', 'ใต้', 'ตอน', 'ล่าง', 'มี', 'ฝน', 'ตก', 'หนัก', 'บาง', 'แห่ง', 'เนื่อง', 'จาก', 'มรสุม', 'ตะวัน', 'ออก', 'เฉียง', 'เหนือ', 'พัด', 'ปกคลุม', 'อ่าวไทย', 'และ', 'ภาค', 'ใต้', 'ส่วน', 'ใน', 'ช่วง', 'วัน', 'ที่', 'พย', 'บริเวณ', 'ความ', 'กด', 'อากาศ', 'สูง', 'หรือ', 'มวล', 'อากาศ', 'เย็น', 'กำลัง', 'ค่อนข้าง', 'แรง', 'อีก', 'ระลอก', 'จาก', 'ประเทศ', 'จีน', 'จะ', 'แผ่', 'เสริม', 'ลง', 'มา', 'ปกคลุม', 'ประเทศ', 'ไทย', 'ตอน', 'บน', 'ทำ', 'ให้', 'ประเทศ', 'ไทย', 'ตอน', 'บน', 'มี', 'อุณหภูมิ', 'ลด', 'ลง', 'องศา', 'เซลเซียส', 'กับ', 'มี', 'อากาศ', 'เย็น', 'และ', 'มี', 'ลม', 'แรง', 'ใน', 'ขณะ', 'ที่', 'มรสุม', 'ตะวัน', 'ออก', 'เฉียง', 'เหนือ', 'ที่', 'พัด', 'ปกคลุม', 'อ่าวไทย', 'ตอน', 'บน', 'และ', 'ภาค', 'ใต้', 'จะ', 'มี', 'กำลัง', 'แรง', 'ขึ้น', 'ทำ', 'ให้', 'ภาค', 'ใต้', 'ตอน', 'ล่าง', 'ยังคง', 'มี', 'ฝน', 'ตก', 'หนัก', 'บาง', 'แห่ง', 'ส่วน', 'คลื่น', 'ลม', 'บริเวณ', 'อ่าวไทย', 'ตอน', 'บน', 'มี', 'กำลัง', 'ปานกลาง', 'โดย', 'มี', 'คลื่น', 'สูง', 'ประมาณ', 'เมตร', 'บริเวณ', 'ที่', 'มี', 'ฝนฟ้า', 'คะนอง', 'คลื่น', 'สูง', 'มาก', 'กว่า', 'เมตร', 'อนึ่ง', 'สำหรับ', 'พายุ', 'โซนร้อน', 'อัสนี', 'พายุ', 'ระดับ', 'ทาง', 'เหนือ', 'ของ', 'ประเทศ', 'ฟิลิปปินส์', 'มี', 'แนวโน้ม', 'จะ', 'อ่อน', 'กำลัง', 'ลง', 'ใน', 'ช่วง', 'วัน', 'ที่', 'พย', 'โดย', 'พายุ', 'นี้', 'ไม่', 'มี', 'ผล', 'กระทบ', 'ต่อ', 'ประเทศ', 'ไทย', 'ส่วน', 'ใน', 'ช่วง', 'วัน', 'ที่', 'พย', 'จะ', 'มี', 'หย่อม', 'ความ', 'กด', 'อากาศ', 'ต่ำ', 'กำลัง', 'แรง', 'เคลื่อน', 'ตัว', 'ผ่าน', 'บริเวณ', 'ประเทศ', 'เวียดนาม', 'ตอน', 'กลาง', 'ขอ', 'ให้', 'ประชาชน', 'บริเวณ', 'ประเทศ', 'ไทย', 'ตอน', 'บน', 'ดูแล', 'สุขภาพ', 'เนื่อง', 'จาก', 'สภาพ', 'อากาศ', 'ที่', 'แปรปรวน', 'ไว้', 'ด้วย', 'และ', 'ประชาชน', 'บริเวณ', 'ภาค', 'ใต้', 'ระวัง', 'อันตราย', 'จาก', 'ฝน', 'ที่', 'ตก', 'หนัก', 'และ', 'ฝน', 'ที่', 'ตก', 'สะสม', 'ไว้', 'ด้วย', 'ใน', 'ช่วง', 'วัน', 'ที่', 'พย', 'ขอ', 'ให้', 'เกษตรกร', 'เตรียม', 'การ', 'ป้องกัน', 'และ', 'ระวัง', 'ความ', 'เสียหาย', 'ที่', 'จะ', 'เกิด', 'ต่อ', 'ผล', 'ผลิต', 'ทาง', 'การ', 'เกษตร', 'ไว้', 'ด้วย', 'บริเวณ', 'ความ', 'กด', 'อากาศ', 'สูง', 'จาก', 'ประเทศ', 'จีน', 'ได้', 'แผ่', 'ลง', 'มา', 'ปกคลุม', 'ภาค', 'เหนือ', 'ตอน', 'บน', 'และ', 'ภาค', 'ตะวัน', 'ออก', 'เฉียง', 'เหนือ', 'ใน', 'ระยะ', 'ต้น', 'และ', 'กลาง', 'ช่วง', 'และ', 'แผ่', 'ปกคลุม', 'ประเทศ', 'ไทย', 'ตอน', 'บน', 'ใน', 'ระยะ', 'ปลาย', 'ช่วง', 'ประกอบ', 'กับ', 'ใน', 'วัน', 'แรก', 'ของ', 'ช่วง', 'มี', 'หย่อม', 'ความ', 'กด', 'อากาศ', 'ต่ำ', 'ปกคลุม', 'อยู่', 'บริเวณ', 'ภาค', 'เหนือ', 'และ', 'ภาค', 'ตะวัน', 'ออก', 'เฉียง', 'เหนือ', 'ลักษณะ', 'ดัง', 'กล่าว', 'ทำ', 'ให้', 'บริเวณ', 'ประเทศ', 'ไทย', 'ตอน', 'บน', 'มี', 'อากาศ', 'เย็น', 'เกือบ', 'ทั่วไป', 'ใน', 'ภาค', 'เหนือ', 'และ', 'ภาค', 'ตะวัน', 'ออก', 'เฉียง', 'เหนือ', 'กับ', 'มี', 'ฝน', 'ส่วน', 'มาก', 'ใน', 'ระยะ', 'ต้น', 'ช่วง', 'ส่วน', 'ภาค', 'ใต้', 'มี', 'ฝน', 'ตลอด', 'ช่วง', 'จาก', 'อิทธิพล', 'ของ', 'มรสุม', 'ตะวัน', 'ออก', 'เฉียง', 'เหนือ', 'ที่', 'พัด', 'ปกคลุม', 'อ่าวไทย', 'และ', 'ภาค', 'ใต้', 'เกือบ', 'ตลอด', 'ช่วง', 'ประกอบ', 'กับ', 'มี', 'ร่องมรสุม', 'พาดผ่าน', 'ภาค', 'ใต้', 'ตอน', 'กลาง', 'ใน', 'ระยะ', 'ครึ่ง', 'แรก', 'ของ', 'ช่วง', 'จาก', 'นั้น', 'ได้', 'เลื่อน', 'ลง', 'ไป', 'พาด', 'ผ่าน', 'บริเวณ', 'ภาค', 'ใต้', 'ตอน', 'ล่าง', 'บริเวณ', 'ประเทศ', 'ไทย', 'ตอน', 'บน', 'จะ', 'มี', 'อากาศ', 'หนาวเย็น', 'มาก', 'ขึ้น', 'โดย', 'เฉพาะ', 'ใน', 'ระยะ', 'ครึ่ง', 'หลัง', 'ของ', 'เดือน', 'กับ', 'จะ', 'มี', 'หมอก', 'หนา', 'หลาย', 'พื้นที่', 'ใน', 'บาง', 'ช่วง', 'บริเวณ', 'เทือกเขา', 'ยอด', 'ดอย', 'และ', 'ยอด', 'ภู', 'จะ', 'มี', 'อากาศ', 'หนาว', 'ถึง', 'หนาว', 'จัด', 'กับ', 'มี', 'น้ำ', 'ค้าง', 'แข็ง', 'เกิด', 'ขึ้น', 'ได้', 'ใน', 'บาง', 'วัน', 'สำหรับ', 'ภาค', 'ใต้', 'ฝั่ง', 'ตะวัน', 'ออก', 'ยังคง', 'มี', 'ฝน', 'ตก', 'ชุก', 'หนาแน่น', 'กับ', 'จะ', 'มี', 'ฝน', 'ตก', 'หนัก', 'บาง', 'แห่ง', 'ใน', 'บาง', 'วัน', 'โดย', 'เฉพาะ', 'ตั้งแต่', 'จังหวัดสุราษฎร์ธานี', 'ลง', 'ไป', 'คลื่น', 'ลม', 'ใน', 'ทะเล', 'อ่าวไทย', 'ยังคง', 'มี', 'กำลัง', 'แรง', 'จะ', 'มี', 'คลื่น', 'สูง', 'เมตร', 'ใน', 'บาง', 'ช่วง', 'ส่วน', 'ภาค', 'ใต้', 'ฝั่ง', 'ตะวัน', 'ตก', 'ฝน', 'จะ', 'ลด', 'ลง', 'คลื่น', 'ลม', 'ทะเล', 'อันดามัน', 'จะ', 'มี', 'คลื่น', 'สูง', 'เมตร', 'เนื่อง', 'จาก', 'บริเวณ', 'ความ', 'กด', 'อากาศ', 'สูง', 'จาก', 'ประเทศ', 'จีน', 'ยังคง', 'แผ่', 'เสริม', 'ลง', 'มา', 'ปกคลุม', 'ประเทศ', 'ไทย', 'ตอน', 'บน', 'เป็น', 'ระยะ', 'โดย', 'จะ', 'มี', 'กำลัง', 'ค่อนข้าง', 'แรง', 'และ', 'ต่อเนื่อง', 'ประกอบ', 'กับ', 'มรสุม', 'ตะวัน', 'ออก', 'เฉียง', 'เหนือ', 'กำลัง', 'แรง', 'ยังคง', 'พัด', 'ปกคลุม', 'ประเทศ', 'ไทย', 'นอก', 'จาก', 'นี้', 'จะ', 'มี', 'ร่องมรสุม', 'พาด', 'ผ่าน', 'บริเวณ', 'ภาค', 'ใต้', 'ตอน', 'ล่าง', 'ใน', 'บาง', 'ช่วง', 'สรุป', 'เดือน', 'นี้', 'คาด', 'ว่า', 'ปริมาณ', 'ฝน', 'รวม', 'บริเวณ', 'ประเทศ', 'ไทย', 'ตอน', 'บน', 'จะ', 'สูง', 'กว่า', 'ค่า', 'ปกติ', 'ประมาณ', 'ร้อยละ', 'ส่วน', 'ภาค', 'ใต้', 'จะ', 'สูง', 'กว่า', 'ค่า', 'ปกติ', 'ร้อย', 'ละ', 'ส่า', 'หรับ', 'อุณหภูมิ', 'เฉลี่ย', 'จะ', 'สูง', 'กว่า', 'ค่า', 'ปกติ', 'ประมาณ', 'องศา', 'เซลเซียส', 'สวัสดี', 'ค่ะ']\n",
      "810\n"
     ]
    }
   ],
   "source": [
    "print(ytrain)\n",
    "print(len(ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = word_vector.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51358\n",
      "51358\n"
     ]
    }
   ],
   "source": [
    "vecter = []\n",
    "vocab_ = []\n",
    "index = 0\n",
    "for word in w2v.index2word:\n",
    "    vocab_.append(word)\n",
    "    vecter.append(w2v[word])\n",
    "print(len(vocab_))\n",
    "print(len(vecter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2idx(x):\n",
    "    xidx = []\n",
    "    for w in x:\n",
    "#         print(w)\n",
    "        if w in vocab_:\n",
    "            xidx.append(vocab_.index(w))\n",
    "        else:\n",
    "            vocab_.append(w)\n",
    "#             np.vstack((vecter,np.random.rand(*vecter[0].shape)))\n",
    "            vecter.append(np.random.rand(*vecter[0].shape))\n",
    "            xidx.append(vocab_.index(w))\n",
    "    return np.array(xidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51358\n",
      "51358\n"
     ]
    }
   ],
   "source": [
    "# print(vecter[1])\n",
    "print(len(vocab_))\n",
    "print(len(vecter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_seq(words):\n",
    "    Xtrain_idx = []\n",
    "    maxlen = 0\n",
    "    for x in words:\n",
    "        Xtrain_idx.append(sent2idx(x))\n",
    "        if len(Xtrain_idx[-1]) > maxlen:\n",
    "            maxlen = len(Xtrain_idx[-1])\n",
    "#         print(len(Xtrain_idx[-1]))\n",
    "    return Xtrain_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "พยากรณ์อากาศ\n"
     ]
    }
   ],
   "source": [
    "print(vocab_[24325])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24326  1383   771   220   213   100  1858  1162   258    31  2067  1162\n",
      "  1930   332  4938    18    71   320  4330  3240    71    86   318   135\n",
      "   395    14     5 16599   100  1858  1162  1314  3240   213    71  1151\n",
      "   218   106    36   101    21    71    86   318   135     5  3222    85\n",
      "    54    14     5  1162  1930    98   213   749  2922     2 51359     5\n",
      "  1162  6524   112  8949  3606    82  8184   454  4256  3240  7068     2\n",
      "   276   377   101    21   276   377     5  3222   704  2044  3730  2768\n",
      " 51360 13178  2768   173   213  3606   704  8184   377     4   408  2233\n",
      "     5  9181     1    15  1328   332   110     2    48     5   371  4560\n",
      "    84    71    86 51361   145   129     1 27740   213   100  1858  1162\n",
      "   258    31  2067  1162  1930   332  4938    18    71   320  3240    71\n",
      "    86   318   135   395    14     5 16599   100  1858  1162  1314  3240\n",
      "   213    71  1151   218   106    36   101    21   213    71    86   318\n",
      "   135     5  1162  1930    14     5  3222  1450    72  4938    11   801\n",
      "   213   276  3606    82  8184   454   318  1850     2   276  3606    82\n",
      "   112   276   377   318  1850     5  3222   704  1770   237    49  6536\n",
      "    18  8949  3606    82  8184   454  4256  3240  7068     2   276   377\n",
      "    98 51361   145   129     1 27740   213   100  1858  1162   258    31\n",
      "  2067  1162  1930   332  1583  1025    90 16181    18    71   320    15\n",
      "  4330  1534   110    29  3240    71    86   318   135   101    21    71\n",
      "    86   318   135     5  1332   283   110  1711 27464    14     5  1162\n",
      "  1930     2     5   811  1025 51361  1014     1  8949  3606    82  8184\n",
      "   454     1  4256  3240  7068   318   135     2   276   377    15     5\n",
      "   332  1025    54   101    21   276   377   318  1850   560     5  3222\n",
      "   704  1770   237    49    98  1492   811   213  7068   318   135     5\n",
      "   332  4938    11     5  1492   258   197   587   213     1     5 51362\n",
      " 17771  1492   258   111   151   587  3730   112  2768 51360 13178  2768\n",
      "   173    53   454     4    71  1578     5  9181    15  1328   332   110\n",
      " 51361   145   129     1 27740    11  2768    36    48     5   371  4560\n",
      "    84    71    86    98 51361   145   129     1 27740    15     5 16599\n",
      "   100  1858  1162  1314   332  1025  2947   120   227   213    71   888\n",
      "   318   348   350    21   403   213    71    86   318   135   920  1537\n",
      "  6536    18   898  1162     1 11182   133    44     2   403   213   276\n",
      "   377  5465  2480    18  3222     1   704  1770     2  3222     1   704\n",
      "  1648   133    44 51361   145   129     1 27740   350    21  4786  1609\n",
      "     8   720     2  5465   100  3770     1    15    85    84   371   466\n",
      "    53     8  2788   133    44   213   100  1858  1162   258    18    71\n",
      "   320     6  4330   110    29  3240   276   454   318   135     2   276\n",
      "  3606    82  8184   454 51361  1174   632     2   348   145     2  4330\n",
      "  3240    71    86   318   135 51361  1174   614   145   395    14 51361\n",
      "   129   107     4   145     5 16599   100  1858  1162  1314  3240    34\n",
      "   213   276   454     2   276  3606    82  8184   454   218  1021   817\n",
      "   101    21   213    71    86   318   135     5  1162  1930  1198   491\n",
      " 51361   276   454     2   276  3606    82  8184   454    14     5  3222\n",
      "    98   111 51361  1174   632   145    98   276   377     5  3222   927\n",
      "   145    18  1350     4  8949  3606    82  8184   454     1  4256  3240\n",
      "  7068     2   276   377  1198   927   145   395    14     5 51363 51364\n",
      "   276   377   318   348 51361  1174  1626   107     4   145    18    58\n",
      "     6  1853   110    24  5684   227   213   276   377   318  1850   213\n",
      "    71    86   318   135    15     5  1162  9449   111    54    11   801\n",
      " 51361  1174  1626   202     4   134    14    15     5  5746  1928   127\n",
      "   206 51361   237   145   213  2269   749  2922     2   749  1283    15\n",
      "     5  1162  6524    72  6524   140    14     5   275  7599  2201    85\n",
      "    54     6 51361   237   129   112   276   377  1080  3606    82   560\n",
      "     5  3222   704  6991  4153    14    15     5  3222   704  1770   237\n",
      "    49 51361   237   129    11   801   149 51365   110    24  1492   811\n",
      " 51361   714  7068   560     5   332  1025    15     5  1492   258   587\n",
      " 51361   237   145    98   276   377  1080  3606   704  3222    15   283\n",
      "   110  1492   811   714  6997    15     5  1492   258   587  6536    18\n",
      "   213   100  1858  1162   258    18    71   320   560  4330  1534   110\n",
      "    29  3240    71    86   318   135     3  1174    11    15     5   332\n",
      "  1583  1025     2  2044   395    14  8949  3606    82  8184   454   332\n",
      "  1025   560  4256  3240    71    86  1034    18    36    15     5 51363\n",
      "  5684   227   213   276   377   318  1850 51361   237   145  2156   134\n",
      "    36  1845    17  1295  3222   228   213    71    86   318   135    15\n",
      "   258   151   795   990   197  1499    98   276   377    15   258   151\n",
      "   795   990  1567   682 20613 18146  1332  2692    15   258   151   795\n",
      "   990   197  1711 27464 10967 13586]\n"
     ]
    }
   ],
   "source": [
    "Ytrain = np.array(sent2idx(ytrain))\n",
    "print(Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_ = [''] + vocab_\n",
    "# vecter = np.vstack((np.random.rand(*vecter[0].shape), vecter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51366\n",
      "51366\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab_))\n",
    "print(len(vecter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "810\n",
      "(810, 2)\n"
     ]
    }
   ],
   "source": [
    "Xtrain = np.array(word_seq(xtrain))\n",
    "Xtrain = sequence.pad_sequences(np.array(Xtrain),padding='pre')\n",
    "print(len(Xtrain))\n",
    "print(Xtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_int = {}\n",
    "int_to_char = {}\n",
    "index = 0\n",
    "for word_ in vocab_:\n",
    "    char_to_int[word_] = vocab_.index(word_)\n",
    "    int_to_char[vocab_.index(word_)] = word_\n",
    "    index  += 1\n",
    "#     if index == 100:\n",
    "#         break\n",
    "# print(int_to_char)\n",
    "# print(char_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoded = []\n",
    "for value in Ytrain:\n",
    "\tletter = [0 for _ in range(len(vocab_))]\n",
    "\tletter[value] = 1\n",
    "\tonehot_encoded.append(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(810, 51366)\n"
     ]
    }
   ],
   "source": [
    "Ytrain = np.array(onehot_encoded)\n",
    "# print(onehot_encoded[0].shape)\n",
    "vocab_size = len(vocab_) + 1\n",
    "print(Ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "810\n"
     ]
    }
   ],
   "source": [
    "print(len(onehot_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "พยากรณ์อากาศ\n"
     ]
    }
   ],
   "source": [
    "inverted = int_to_char[argmax(onehot_encoded[0])]\n",
    "print(inverted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "810\n"
     ]
    }
   ],
   "source": [
    "target = []\n",
    "for i in range(len(xtrain)):\n",
    "    target.append(1)\n",
    "\n",
    "target = np.array(target)\n",
    "print(target)\n",
    "print(len(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "thai_letters = 'กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรฤฤๅลฦฦๅวศษสหฬอฮะัาำิีึืุูเแโใไ็่้๊๋์'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    }
   ],
   "source": [
    "print(len(thai_letters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_int1 = dict((c, i) for i, c in enumerate(thai_letters,start=1))\n",
    "int_to_char1 = dict((i, c) for i, c in enumerate(thai_letters,start=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "integer_encoded1 = []\n",
    "for i in ytrain:\n",
    "    integer_encoder = [char_to_int1[char] for char in i]\n",
    "    integer_encoded1.append(integer_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(810, 30)\n",
      "810\n"
     ]
    }
   ],
   "source": [
    "input1 = len(thai_letters) + 1\n",
    "max_len = 30\n",
    "integer_encoded1 = sequence.pad_sequences(np.array(integer_encoded1),maxlen=max_len,padding='pre')\n",
    "print(integer_encoded1.shape)\n",
    "print(len(integer_encoded1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_input = keras.layers.Input(shape=(vocab_size,),name='context_input')\n",
    "word_embeddings = keras.layers.Embedding(input_dim=vecter.shape[0],\n",
    "                                         output_dim=vecter.shape[1],input_length=2,\n",
    "                                         name='embed',trainable=False)(context_input)\n",
    "\n",
    "char_in = keras.layers.Input(shape=(vocab_size,max_len,), name='char_input')\n",
    "\n",
    "emb_char = keras.layers.TimeDistributed(keras.layers.Embedding(input_dim=input1,output_dim=128,input_length=max_len))(char_in)\n",
    "char_enc = keras.layers.TimeDistributed(keras.layers.Bidirectional(keras.layers.LSTM(64)))(emb_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_word_embeddings = keras.layers.concatenate([word_embeddings, char_enc])\n",
    "main_lstm = keras.layers.Bidirectional(keras.layers.LSTM(units=128, return_sequences=True))(all_word_embeddings)\n",
    "main_lstm = keras.layers.TimeDistributed(keras.layers.Dense(2,activation=keras.activations.relu))(main_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model([char_in,context_input], main_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=keras.losses.categorical_crossentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         [(None, 51367, 30)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "context_input (InputLayer)      [(None, 51367)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_57 (TimeDistri (None, 51367, 30, 12 9216        char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embed (Embedding)               (None, 51367, 300)   15409800    context_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_58 (TimeDistri (None, 51367, 128)   98816       time_distributed_57[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 51367, 428)   0           embed[0][0]                      \n",
      "                                                                 time_distributed_58[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_30 (Bidirectional (None, 51367, 256)   570368      concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_59 (TimeDistri (None, 51367, 2)     514         bidirectional_30[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 16,088,714\n",
      "Trainable params: 678,914\n",
      "Non-trainable params: 15,409,800\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 51367, 30) for input Tensor(\"char_input_23:0\", shape=(None, 51367, 30), dtype=float32), but it was called on an input with incompatible shape (None, 30).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 51367) for input Tensor(\"context_input_29:0\", shape=(None, 51367), dtype=float32), but it was called on an input with incompatible shape (None, 2).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    E:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    E:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    E:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    E:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    E:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    E:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    E:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:747 train_step\n        y_pred = self(x, training=True)\n    E:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    E:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:385 call\n        return self._run_internal_graph(\n    E:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:508 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    E:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:975 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    E:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:176 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer time_distributed_57 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [None, 30]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-149-afc9397a0fc0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minteger_encoded1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    812\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2826\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2828\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2829\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3208\u001b[0m           \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3209\u001b[0m           and call_context_key in self._function_cache.missed):\n\u001b[1;32m-> 3210\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_define_function_with_shape_relaxation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3139\u001b[0m           expand_composites=True)\n\u001b[0;32m   3140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3141\u001b[1;33m     graph_function = self._create_graph_function(\n\u001b[0m\u001b[0;32m   3142\u001b[0m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0;32m   3143\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3065\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    E:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    E:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    E:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    E:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    E:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    E:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    E:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:747 train_step\n        y_pred = self(x, training=True)\n    E:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    E:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:385 call\n        return self._run_internal_graph(\n    E:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:508 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    E:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:975 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    E:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:176 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer time_distributed_57 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [None, 30]\n"
     ]
    }
   ],
   "source": [
    "model.fit([integer_encoded1,Xtrain],target,epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1 = keras.Sequential()\n",
    "# model1.add(keras.layers.Embedding(input_dim = input1,output_dim = 300,input_length=max_len))\n",
    "# model1.add(keras.layers.Bidirectional(keras.layers.LSTM(64, return_sequences=True)))\n",
    "# # model1.add(keras.layers.Dense(2,activation=keras.activations.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2 = keras.Sequential()\n",
    "# model2.add(keras.layers.Embedding(vecter.shape[0], vecter.shape[1], name='embed'))\n",
    "# model2.add(keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True)))\n",
    "# model2.add(keras.layers.Dense(2,activation=keras.activations.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_model = keras.layers.Concatenate([model1,model2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
