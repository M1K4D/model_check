{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepcut\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow import keras\n",
    "from pythainlp import word_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ส่วนบริเวณยอดดอยและยอดภูมีอากาศหนาว', 'ส่วนบริเวณยอดดอยและยอดภูมีอากาสหนว', 'ได้อ่อนกำลังลงเป็นหย่อมความกดอากาศต่ำกำลังแรงบริเวณใกล้ชายฝั่งประเทศเวียดนามตอนกลางแล้ว', 'ได้อ่อนกำลังลงเป็ยหย่อมความกดอากาสต่ำกำลังแรงบริเวณใกล้ชายฝั่งประเทศเวียตนามตอนกลงแล้ว', 'บริเวณภาคตะวันออกเฉียงเหนือตอนล่าง และภาคตะวันออก มีฝนเล็กน้อยถึงปานกลางกับมีลมแรง', 'บริฌวณถาคตะวันออกเฉียงเหนีอตอนล่าง และถาคตะวันออก มีฝนเล็กน้อยถึงปานกลษงกับมีลมแรง', 'บริเวณความกดอากาศสูงกำลังปานกลางหรือมวลอากาศเย็นจากประเทศจีนแผ่ปกคลุมประเทศไทยตอนบน', 'บริเวณคาวมกดอากาสสูงกำลังปานกลางหรือมวลอากาศเย็ฯจากประเทสจืนแผ่ปกคลุมประเทศไทยตอนบน', 'ได้เคลื่อนขึ้นฝั่งบริเวณดังกล่าวและคาดว่าจะอ่อนกำลังลงอีกเป็นหย่อมความกดอากาศต่ำในระยะต่อไป', 'ได้เคลิ่อนขึ้นฝั่งบริเวณดังกล่วและคาดว่าจะอ่อนกำลังลงอีกเป็ฯหย่อมความกดอากาศต่ำในระยะต่อไป', 'ทำให้บริเวณดังกล่าวมีอากาศเย็น โดยมีฝนบางแห่ง', 'ทำให้บริเวญดังกล่วมีอากาศเย็ฯโดยมีฝนบางแห่ง', 'ส่วนบริเวณยอดดอยและยอดภูมีอากาศหนาว สำหรับมรสุมตะวันออกเฉียงเหนือพัดปกคลุมอ่าวไทยและภาคใต้', 'ส่วนบริเวณยอดดอยและยอดภู มีอากาศหนว สำหรับมรสุมตะวันออกเฉียงเหนีอพัดปกครุมอ่าวไทยและภากใต้', 'พายุโซนร้อนได้อ่อนกำลังลงเป็นพายุดีเปรสชันแล้ว', 'พายุโซนร้อนได้อ่อนกำลังลงเป็ฯพายุดีเปรดชันแล้ง', 'อ่อนกำลังลงเป็นหย่อมความกดอากาศต่ำบริเวณประเทศกัมพูชา', 'อ่อนกำลังลงเป็นหย่อมคาวมกดอากาสต่ำบริเวณประเทศกัมภูชา', 'ส่งผลทำให้ในช่วงบริเวณภาคตะวันออกเฉียงเหนือตอนล่าง และภาคตะวันออก มีฝนเล็กน้อยถึงปานกลางกับมีลมแรง', 'ส่งผลทำให้ในช่วงบริเวณถาคตะวันออกเฉียงเหนือตอนล่าง และภากตะวันออก มีฝนเล็กน้อยถึงปาฯกลางกับมีลมแรง', 'ขอให้ประชาชนบริเวณประเทศไทยตอนบนดูแลสุขภาพเนื่องจากสภาพอากาศที่เปลี่ยนแปลงไว้ด้วย', 'ขอให้ประชาชนบริเวณประเทศไทยตอนบนดูแลสุขภาพเนิ่องจากสะภาพอากาสที่เปลี่ยนแปรงไว้ด้วย', 'สำหรับร่องมรสุมกำลังปานกลางพาดผ่านภาคใต้ตอนล่างทำให้บริเวณดังกล่าวยังคงมีฝนตกหนักในระยะนี้', 'สำหรับร่องมรสุมกำลังปานกลางพาดผ่านภาคใต้ตอนล่างทำให้บริเวณดังกล่วยังคงมีฝฯตกหนักในระยะนื้', 'มีฝนปานกลางถึงหนักบางแห่งในภาคตะวันออกเฉียงเหนือตอนล่าง และภาคตะวันออก', 'มีฝนปาฯกลางถึงหนักบางแห่งในภากตะวันออกเฉียงเหนือตอนล่าง และภาคตะวันออก', 'บริเวณความกดอากาศสูงกำลังปานกลางหรือมวลอากาศเย็นจากประเทศจีนแผ่ปกคลุมประเทศไทยตอนบน', 'บริเวณความกดอากาศสูงกำลังปานกลางหรือมวลอากาศเย็นจากประเทศจืนแผ่ปกคลุมประเทศไทยตอนบน', 'พายุดีเปรสชันได้อ่อนกำลังลงเป็นหย่อมความกดอากาศต่ำกำลังแรงบริเวณใกล้ชายฝั่งประเทศเวียดนามตอนกลาง', 'พายุดีเปรสชันได้อ่อนกำลังลงเป็นหย่อมควมกดอษกาศต่ำกำลังแรงบริเวณใกล้ชายฝั่งประเทศเวียตนามตอนกลง', 'มีแนวโน้มเคลื่อนขึ้นฝั่งบริเวณประเทศเวียดนามตอนกลางแล้วจะอ่อนกำลังลงตามลำดับ', 'มีแนวโน้มเคลิ่อฯขึ้นฝั่งบริเวณปณะเทศเวียกนามตอนกลงแล้วจะอ่อนกำลังลงตามลำดับ', 'สำหรับร่องมรสุมกำลังปานกลางพาดผ่านภาคใต้ตอนล่าง ทำให้ภาคใต้ยังคงมีฝนตกหนักในระยะนี้', 'สำหรับร่องมรสุมกำลังปานกลางพาดผ่านภาคใต้ตอนล่าง ทำให้ภาคใต้ยังคงมีฝนตดหนักในระยะนี้', 'ดูแลสุขภาพเนื่องจากสภาพอากาศที่เปลี่ยนแปลง', 'ดูแลสุขภาบเนื่องจากสภาพอากาสที่เปลี่ยนแปรง', 'บริเวณด้านตะวันออกของประเทศฟิลิปปินส์ จะเคลื่อนลงสู่ทะเลจีนใต้ตอนกลาง', 'บริเวณด้านตะวันออกของประเทศฟิลิปปิน จะเคลื่อนลงสู่ทะเลจีนใต้ตอนกลง', 'มีฝนเล็กน้อยบางแห่งในภาคเหนือ ภาคตะวันออกเฉียงเหนือ และภาคกลาง', 'มีฝนเล็กน้อฯบางแห่วในภาคเหนือ ภากตะวันออกเฉียงเหนือ และภาคกลาง', 'คลื่นลมบริเวณทะเลอันดามันและอ่าวไทยจะมีกำลังแรง โดยบริเวณทะเลอันดามันและอ่าวไทยตอนบนมีคลื่นสูง', 'คลื่นลมบริเวณทะเลอันดามันและอ่าวไทยจะมีกำลังแรง โดยบริเวณทะเลอัฯดามันและอ่าวไทยตอนบฯมีคลื่นสูง', 'ทำให้ประเทศไทยตอนบนมีฝนเป็นบริเวณกว้าง', 'ทำให้ประเทศไทยตอยบนมีฝนเป็นบริเวณกว้าง', 'โดยมีฝนตกหนักหลายพื้นที่', 'โดยมีฝนตกหนักหลยฟื้นที่', 'มีฝนตกหนักมากบางแห่กับมีลมแรง', 'มีฝนตกหนัดมากบาวแห่งกับมีลมแรง', 'ขอให้ชาวเรือในบริเวณดังกล่าวเดินเรือด้วยความระมัดระวังในช่วงที่มีฝนฟ้าคะนอง', 'ขอให้ชาวเรือในบริเวณดังกล่วเดินเรีอด้วยความระมัดระวังในช่วงที่มีฝนฟ้าคะนอง']\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "with open('corpus.txt') as f:\n",
    "    xtrain = []\n",
    "    ytrain = []\n",
    "    for line in f.readlines():\n",
    "        temp = line.split()\n",
    "        if len(temp) == 2:\n",
    "            xtrain.append(temp[0])\n",
    "            ytrain.append(temp[-1])\n",
    "        elif len(temp) > 2:\n",
    "            join = \" \".join(temp[0:-1])\n",
    "            xtrain.append(join)\n",
    "            ytrain.append(temp[-1])\n",
    "#         print(line)\n",
    "print(xtrain)\n",
    "print(len(xtrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด']\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "print(ytrain)\n",
    "print(len(ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = ['วันนี้วันจันทร์','วันนี้วันศุกร์','วันนี้วันเสาร์','วันนีวันจันทนะ','วันนีวันศุกนะ','วันนีวันศุร์นะ','วันนี้วันศุกร์นะ','วันนี้วันจันทร์นะ',]\n",
    "# y_train = ['ถูก','ถูก','ถูก','ผิด','ผิด','ผิด','ถูก','ถูก',]\n",
    "# x_test = ['วันนี้วันพุธ','วันนี้วันอังคาร','วันนี้วันอังคาน','วันนี้วัลพุธ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus = ['วันนี้วันจันทร์','วันนี้วันศุกร์','วันนี้วันเสาร์','วันนีวันจันทนะ','วันนีวันศุกนะ',\n",
    "#           'วันนีวันศุร์นะ','วันนี้วันศุกร์นะ','วันนี้วันจันทร์นะ','วันนี้วันพุธ','วันนี้วันอังคาร','วันนี้วันอังคาน','วันนี้วัลพุธ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['วัน', 'นี้', 'วัน', 'ศุร์นะ']\n"
     ]
    }
   ],
   "source": [
    "test = deepcut.tokenize('วันนี้วันศุร์นะ')\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_tokenize(corpus):\n",
    "    x = 0\n",
    "    words = []\n",
    "    for i in corpus:\n",
    "        list_word = deepcut.tokenize(i,custom_dict='custom_dict.txt') #ตัดคำ\n",
    "        words.append(list_word)\n",
    "        x += 1\n",
    "    return words\n",
    "# corpus=word_tokenize(corpus)\n",
    "# x_test = word_tokenize(x_test)\n",
    "words = word_tokenize(xtrain)\n",
    "# print(words)\n",
    "# print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 'ภากใต้', 'ใน', 'หลย', 'ไป', 'เหนีอพัด', 'เนื่อง', 'ลง', 'นี้', 'เย็น', 'ตอนกลง', 'ยอด', 'ไว้', 'จืน', 'ด้าน', 'ตอยบน', 'อีก', 'พื้นที่', 'พัด', 'ดูแล', 'สุขภาพ', 'ลม', 'ตาม', 'ช่วง', 'อันดามัน', 'ผล', 'บริเวณ', 'ฝั่ง', 'เคลื่อน', 'จะ', 'ควม', 'ชัน', 'สะภาพ', 'ประเทศฟิลิปปินส์', 'ความ', 'ประเทศฟิลิปปิน', 'สุขภาบ', 'นื้', 'หนัด', 'จาก', 'แผ่', 'ร่อง', 'ยอดภู', 'กว้าง', 'ระมัดระวัง', 'โดย', 'ใต้', 'เปลี่ยนแปลง', 'แล้ง', 'สู่', 'ภาค', 'ชาย', 'คาว', 'ตะวัน', 'ปณะ', 'กำลัง', 'ฝ', 'ปานกลาง', 'คาด', 'อษกาศ', 'ประเทศไทย', 'มี', 'เคลิ่อน', 'แห่', 'สำหรับ', 'ตด', 'ถึง', 'ลำดับ', 'อากาศ', 'เล็กน้อ', 'คาวม', 'ฝน', 'ล่าง', 'เย็ฯ', 'เป็ย', 'ว่า', 'เรีอ', 'ให้', 'ประเทศเวียตนาม', 'ต่อ', 'หลาย', 'กล่าว', 'ทำ', 'อากาส', 'ภาก', 'ม', 'เป็', 'เฉียง', 'หย่อม', 'ที่', 'พาด', 'หนัก', 'เทศ', 'เคลิ่อฯ', 'เวียกนาม', 'ของ', 'โซนร้อน', 'ฝนฟ้า', 'แรง', 'แห่ว', 'ทะเล', 'ปกคลุม', 'ถาค', 'เปลี่ยนแปรง', 'และ', 'จีนใต้', 'กับ', 'สูง', 'ยังคง', 'บริฌวณ', 'ประเทส', 'ประเทศเวียดนาม', 'ปกครุม', 'กด', 'ตก', 'มาก', 'มรสุม', 'บาง', 'หนาว', 'ขอ', 'ระยะ', 'ประเทศกัมภูชา', 'ดัง', 'ภูมี', 'แห่ง', 'ส่วน', 'ต่ำ', ' ', 'ประชาชน', 'ส่ง', 'อัฯดามัน', 'ประเทศ', 'สภาพ', 'ใกล้', 'เนิ่อง', 'หนว', 'เหนีอ', 'แนวโน้ม', 'ปานกลษง', 'ด้วย', 'บาว', 'ถาคตะวัน', 'ฟื้น', 'คะนอง', 'ตอนบฯ', 'เล็กน้อย', 'ประเทศจีน', 'บน', 'มวล', 'ฯ', 'อ่อน', 'ได้', 'เรือ', 'บริเวญ', 'คลื่น', 'แล้ว', 'ขึ้น', 'กล่ว', 'หรือ', 'ดีเปรสชัน', 'ตอน', 'ดอย', 'ดีเปรด', 'ผ่าน', 'ชาว', 'เป็น', 'อ่าวไทย', 'เหนือ', 'ปาฯ', 'ปาน', 'เป็ฯ', 'กลาง', 'พายุ', 'ออก', 'เดิน', 'ประเทศกัมพูชา', 'กลง']\n",
      "177\n"
     ]
    }
   ],
   "source": [
    "def add_1list(word_list):\n",
    "    list_ = []\n",
    "    vocab = []\n",
    "    for l in word_list:\n",
    "        list_.extend(l)\n",
    "#     print(list_)\n",
    "    word_v = set(list_)\n",
    "    for list_d in word_v:\n",
    "        vocab.append(list_d)\n",
    "    vocab = [' '] + vocab\n",
    "    return vocab\n",
    "\n",
    "vocab = add_1list(words)\n",
    "print(vocab)\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words1 = []\n",
    "# x = 0\n",
    "# y = 0\n",
    "# for text in range(len(words)):\n",
    "#     for word in range(len(words[y])):\n",
    "#         words1.append(words[y][x])\n",
    "#         x += 1\n",
    "#     y += 1\n",
    "#     x = 0\n",
    "# print(words1)\n",
    "# words1 = set(words1)\n",
    "# print(words1)\n",
    "# # vocab = []\n",
    "# # for list_d in words1:\n",
    "# #     vocab.append(list_d)\n",
    "# # vocab = [' '] + vocab\n",
    "# # print(vocab)\n",
    "# # print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = word_vector.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2idx(x):\n",
    "    xidx = []\n",
    "    for w in x:\n",
    "#         print(w)\n",
    "        if w in vocab:\n",
    "            xidx.append(vocab.index(w))\n",
    "    return np.array(xidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([125,  26,  11, 161, 104,  11, 123,  68, 118])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2idx(words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_seq(words):\n",
    "    Xtrain_idx = []\n",
    "    maxlen = 0\n",
    "    for x in words:\n",
    "        Xtrain_idx.append(sent2idx(x))\n",
    "        if len(Xtrain_idx[-1]) > maxlen:\n",
    "            maxlen = len(Xtrain_idx[-1])\n",
    "#         print(len(Xtrain_idx[-1]))\n",
    "    return Xtrain_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xtest = word_seq(x_test)\n",
    "# print(Xtest)\n",
    "Xtrain = np.array(word_seq(words))\n",
    "# print(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0 ... 123  68 118]\n",
      " [  0   0   0 ... 123  83 135]\n",
      " [  0   0   0 ... 160 171 155]\n",
      " ...\n",
      " [  0   0   0 ...  61  21  98]\n",
      " [  0   0   0 ...  61  97 143]\n",
      " [  0   0   0 ...  61  97 143]]\n"
     ]
    }
   ],
   "source": [
    "Xtrain = sequence.pad_sequences(np.array(Xtrain),padding='pre')\n",
    "print(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 30)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "intput_lenght = len(Xtrain[0])\n",
    "print(intput_lenght)\n",
    "vocab_size = len(vocab)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xtest = sequence.pad_sequences(np.array(Xtest),maxlen=intput_lenght,padding='pre')\n",
    "# print(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "y_train = []\n",
    "for i in ytrain:\n",
    "    if i == 'ถูก':\n",
    "        y_train.append(1)\n",
    "    else:\n",
    "        y_train.append(0)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(input_dim = vocab_size,output_dim = 300,input_length=intput_lenght))\n",
    "model.add(keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True)))\n",
    "model.add(keras.layers.Bidirectional(keras.layers.LSTM(64)))\n",
    "model.add(keras.layers.Dense(128, activation=keras.activations.relu))\n",
    "model.add(keras.layers.Dense(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy, optimizer=keras.optimizers.SGD(learning_rate=1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 30, 300)           53400     \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 30, 256)           439296    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               164352    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 673,818\n",
      "Trainable params: 673,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.5716\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.9111\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6931\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6931\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6931\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6931\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6931\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6931\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6931\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ee06597100>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain, np.array(y_train), epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(Xtrain).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict(Xtest).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
