{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepcut\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ส่วนบริเวณยอดดอยและยอดภูมีอากาศหนาว', 'ส่วนบริเวณยอดดอยและยอดภูมีอากาสหนว', 'ได้อ่อนกำลังลงเป็นหย่อมความกดอากาศต่ำกำลังแรงบริเวณใกล้ชายฝั่งประเทศเวียดนามตอนกลางแล้ว', 'ได้อ่อนกำลังลงเป็ยหย่อมความกดอากาสต่ำกำลังแรงบริเวณใกล้ชายฝั่งประเทศเวียตนามตอนกลงแล้ว', 'บริเวณภาคตะวันออกเฉียงเหนือตอนล่าง และภาคตะวันออก มีฝนเล็กน้อยถึงปานกลางกับมีลมแรง', 'บริฌวณถาคตะวันออกเฉียงเหนีอตอนล่าง และถาคตะวันออก มีฝนเล็กน้อยถึงปานกลษงกับมีลมแรง', 'บริเวณความกดอากาศสูงกำลังปานกลางหรือมวลอากาศเย็นจากประเทศจีนแผ่ปกคลุมประเทศไทยตอนบน', 'บริเวณคาวมกดอากาสสูงกำลังปานกลางหรือมวลอากาศเย็ฯจากประเทสจืนแผ่ปกคลุมประเทศไทยตอนบน', 'ได้เคลื่อนขึ้นฝั่งบริเวณดังกล่าวและคาดว่าจะอ่อนกำลังลงอีกเป็นหย่อมความกดอากาศต่ำในระยะต่อไป', 'ได้เคลิ่อนขึ้นฝั่งบริเวณดังกล่วและคาดว่าจะอ่อนกำลังลงอีกเป็ฯหย่อมความกดอากาศต่ำในระยะต่อไป', 'ทำให้บริเวณดังกล่าวมีอากาศเย็น โดยมีฝนบางแห่ง', 'ทำให้บริเวญดังกล่วมีอากาศเย็ฯโดยมีฝนบางแห่ง', 'ส่วนบริเวณยอดดอยและยอดภูมีอากาศหนาว สำหรับมรสุมตะวันออกเฉียงเหนือพัดปกคลุมอ่าวไทยและภาคใต้', 'ส่วนบริเวณยอดดอยและยอดภู มีอากาศหนว สำหรับมรสุมตะวันออกเฉียงเหนีอพัดปกครุมอ่าวไทยและภากใต้', 'พายุโซนร้อนได้อ่อนกำลังลงเป็นพายุดีเปรสชันแล้ว', 'พายุโซนร้อนได้อ่อนกำลังลงเป็ฯพายุดีเปรดชันแล้ง', 'อ่อนกำลังลงเป็นหย่อมความกดอากาศต่ำบริเวณประเทศกัมพูชา', 'อ่อนกำลังลงเป็นหย่อมคาวมกดอากาสต่ำบริเวณประเทศกัมภูชา', 'ส่งผลทำให้ในช่วงบริเวณภาคตะวันออกเฉียงเหนือตอนล่าง และภาคตะวันออก มีฝนเล็กน้อยถึงปานกลางกับมีลมแรง', 'ส่งผลทำให้ในช่วงบริเวณถาคตะวันออกเฉียงเหนือตอนล่าง และภากตะวันออก มีฝนเล็กน้อยถึงปาฯกลางกับมีลมแรง', 'ขอให้ประชาชนบริเวณประเทศไทยตอนบนดูแลสุขภาพเนื่องจากสภาพอากาศที่เปลี่ยนแปลงไว้ด้วย', 'ขอให้ประชาชนบริเวณประเทศไทยตอนบนดูแลสุขภาพเนิ่องจากสะภาพอากาสที่เปลี่ยนแปรงไว้ด้วย', 'สำหรับร่องมรสุมกำลังปานกลางพาดผ่านภาคใต้ตอนล่างทำให้บริเวณดังกล่าวยังคงมีฝนตกหนักในระยะนี้', 'สำหรับร่องมรสุมกำลังปานกลางพาดผ่านภาคใต้ตอนล่างทำให้บริเวณดังกล่วยังคงมีฝฯตกหนักในระยะนื้', 'มีฝนปานกลางถึงหนักบางแห่งในภาคตะวันออกเฉียงเหนือตอนล่าง และภาคตะวันออก', 'มีฝนปาฯกลางถึงหนักบางแห่งในภากตะวันออกเฉียงเหนือตอนล่าง และภาคตะวันออก', 'บริเวณความกดอากาศสูงกำลังปานกลางหรือมวลอากาศเย็นจากประเทศจีนแผ่ปกคลุมประเทศไทยตอนบน', 'บริเวณความกดอากาศสูงกำลังปานกลางหรือมวลอากาศเย็นจากประเทศจืนแผ่ปกคลุมประเทศไทยตอนบน', 'พายุดีเปรสชันได้อ่อนกำลังลงเป็นหย่อมความกดอากาศต่ำกำลังแรงบริเวณใกล้ชายฝั่งประเทศเวียดนามตอนกลาง', 'พายุดีเปรสชันได้อ่อนกำลังลงเป็นหย่อมควมกดอษกาศต่ำกำลังแรงบริเวณใกล้ชายฝั่งประเทศเวียตนามตอนกลง', 'มีแนวโน้มเคลื่อนขึ้นฝั่งบริเวณประเทศเวียดนามตอนกลางแล้วจะอ่อนกำลังลงตามลำดับ', 'มีแนวโน้มเคลิ่อฯขึ้นฝั่งบริเวณปณะเทศเวียกนามตอนกลงแล้วจะอ่อนกำลังลงตามลำดับ', 'สำหรับร่องมรสุมกำลังปานกลางพาดผ่านภาคใต้ตอนล่าง ทำให้ภาคใต้ยังคงมีฝนตกหนักในระยะนี้', 'สำหรับร่องมรสุมกำลังปานกลางพาดผ่านภาคใต้ตอนล่าง ทำให้ภาคใต้ยังคงมีฝนตดหนักในระยะนี้', 'ดูแลสุขภาพเนื่องจากสภาพอากาศที่เปลี่ยนแปลง', 'ดูแลสุขภาบเนื่องจากสภาพอากาสที่เปลี่ยนแปรง', 'บริเวณด้านตะวันออกของประเทศฟิลิปปินส์ จะเคลื่อนลงสู่ทะเลจีนใต้ตอนกลาง', 'บริเวณด้านตะวันออกของประเทศฟิลิปปิน จะเคลื่อนลงสู่ทะเลจีนใต้ตอนกลง', 'มีฝนเล็กน้อยบางแห่งในภาคเหนือ ภาคตะวันออกเฉียงเหนือ และภาคกลาง', 'มีฝนเล็กน้อฯบางแห่วในภาคเหนือ ภากตะวันออกเฉียงเหนือ และภาคกลาง', 'คลื่นลมบริเวณทะเลอันดามันและอ่าวไทยจะมีกำลังแรง โดยบริเวณทะเลอันดามันและอ่าวไทยตอนบนมีคลื่นสูง', 'คลื่นลมบริเวณทะเลอันดามันและอ่าวไทยจะมีกำลังแรง โดยบริเวณทะเลอัฯดามันและอ่าวไทยตอนบฯมีคลื่นสูง', 'ทำให้ประเทศไทยตอนบนมีฝนเป็นบริเวณกว้าง', 'ทำให้ประเทศไทยตอยบนมีฝนเป็นบริเวณกว้าง', 'โดยมีฝนตกหนักหลายพื้นที่', 'โดยมีฝนตกหนักหลยฟื้นที่', 'มีฝนตกหนักมากบางแห่กับมีลมแรง', 'มีฝนตกหนัดมากบาวแห่งกับมีลมแรง', 'ขอให้ชาวเรือในบริเวณดังกล่าวเดินเรือด้วยความระมัดระวังในช่วงที่มีฝนฟ้าคะนอง', 'ขอให้ชาวเรือในบริเวณดังกล่วเดินเรีอด้วยความระมัดระวังในช่วงที่มีฝนฟ้าคะนอง']\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "with open('corpus.txt') as f:\n",
    "    xtrain = []\n",
    "    ytrain = []\n",
    "    for line in f.readlines():\n",
    "        temp = line.split()\n",
    "        if len(temp) == 2:\n",
    "            xtrain.append(temp[0])\n",
    "            ytrain.append(temp[-1])\n",
    "        elif len(temp) > 2:\n",
    "            join = \" \".join(temp[0:-1])\n",
    "            xtrain.append(join)\n",
    "            ytrain.append(temp[-1])\n",
    "#         print(line)\n",
    "print(xtrain)\n",
    "print(len(xtrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด', 'ถูก', 'ผิด']\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "print(ytrain)\n",
    "print(len(ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = ['วันนี้วันจันทร์','วันนี้วันศุกร์','วันนี้วันเสาร์','วันนีวันจันทนะ','วันนีวันศุกนะ','วันนีวันศุร์นะ','วันนี้วันศุกร์นะ','วันนี้วันจันทร์นะ',]\n",
    "# y_train = ['ถูก','ถูก','ถูก','ผิด','ผิด','ผิด','ถูก','ถูก',]\n",
    "# x_test = ['วันนี้วันพุธ','วันนี้วันอังคาร','วันนี้วันอังคาน','วันนี้วัลพุธ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus = ['วันนี้วันจันทร์','วันนี้วันศุกร์','วันนี้วันเสาร์','วันนีวันจันทนะ','วันนีวันศุกนะ',\n",
    "#           'วันนีวันศุร์นะ','วันนี้วันศุกร์นะ','วันนี้วันจันทร์นะ','วันนี้วันพุธ','วันนี้วันอังคาร','วันนี้วันอังคาน','วันนี้วัลพุธ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['วัน', 'นี้', 'วัน', 'ศุร์นะ']\n"
     ]
    }
   ],
   "source": [
    "test = deepcut.tokenize('วันนี้วันศุร์นะ')\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['วัน', 'นี้', 'วัน', 'จันทร์'], ['วัน', 'นี้', 'วัน', 'ศุกร์'], ['วัน', 'นี้', 'วัน', 'เสาร์'], ['วัน', 'นีวัน', 'จันทนะ'], ['วัน', 'นีวัน', 'ศุก', 'นะ'], ['วัน', 'นีวัน', 'ศุร์นะ'], ['วัน', 'นี้', 'วัน', 'ศุกร์', 'นะ'], ['วัน', 'นี้', 'วัน', 'จันทร์', 'นะ']]\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "def word_tokenize(corpus):\n",
    "    x = 0\n",
    "    words = []\n",
    "    for i in corpus:\n",
    "        list_word = deepcut.tokenize(i,custom_dict='custom_dict.txt') #ตัดคำ\n",
    "        words.append(list_word)\n",
    "        x += 1\n",
    "    return words\n",
    "corpus=word_tokenize(corpus)\n",
    "x_test = word_tokenize(x_test)\n",
    "words = word_tokenize(x_train)\n",
    "print(words)\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 'ศุร์นะ', 'วัลพุธ', 'พุธ', 'นะ', 'จันทร์', 'นี้', 'จันทนะ', 'อังคาน', 'นีวัน', 'ศุกร์', 'วัน', 'อังคาร', 'เสาร์', 'ศุก']\n"
     ]
    }
   ],
   "source": [
    "def add_1list(word_list):\n",
    "    list_ = []\n",
    "    vocab = []\n",
    "    for l in word_list:\n",
    "        list_.extend(l)\n",
    "#     print(list_)\n",
    "    word_v = set(list_)\n",
    "    for list_d in word_v:\n",
    "        vocab.append(list_d)\n",
    "    vocab = [' '] + vocab\n",
    "    return vocab\n",
    "\n",
    "vocab = add_1list(corpus)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['วัน', 'นี้', 'วัน', 'จันทร์', 'วัน', 'นี้', 'วัน', 'ศุกร์', 'วัน', 'นี้', 'วัน', 'เสาร์', 'วัน', 'นีวัน', 'จันทนะ', 'วัน', 'นีวัน', 'ศุก', 'นะ', 'วัน', 'นีวัน', 'ศุร์นะ', 'วัน', 'นี้', 'วัน', 'ศุกร์', 'นะ', 'วัน', 'นี้', 'วัน', 'จันทร์', 'นะ']\n",
      "{'ศุร์นะ', 'นะ', 'จันทร์', 'นี้', 'จันทนะ', 'นีวัน', 'ศุกร์', 'วัน', 'เสาร์', 'ศุก'}\n"
     ]
    }
   ],
   "source": [
    "words1 = []\n",
    "x = 0\n",
    "y = 0\n",
    "for text in range(len(words)):\n",
    "    for word in range(len(words[y])):\n",
    "        words1.append(words[y][x])\n",
    "        x += 1\n",
    "    y += 1\n",
    "    x = 0\n",
    "print(words1)\n",
    "words1 = set(words1)\n",
    "print(words1)\n",
    "# vocab = []\n",
    "# for list_d in words1:\n",
    "#     vocab.append(list_d)\n",
    "# vocab = [' '] + vocab\n",
    "# print(vocab)\n",
    "# print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2idx(x):\n",
    "    xidx = []\n",
    "    for w in x:\n",
    "#         print(w)\n",
    "        if w in vocab:\n",
    "            xidx.append(vocab.index(w))\n",
    "    return np.array(xidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11,  6, 11,  5])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2idx(words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_seq(words):\n",
    "    Xtrain_idx = []\n",
    "    maxlen = 0\n",
    "    for x in words:\n",
    "        Xtrain_idx.append(sent2idx(x))\n",
    "        if len(Xtrain_idx[-1]) > maxlen:\n",
    "            maxlen = len(Xtrain_idx[-1])\n",
    "#         print(len(Xtrain_idx[-1]))\n",
    "    return Xtrain_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([11,  6, 11,  3]), array([11,  6, 11, 12]), array([11,  6, 11,  8]), array([11,  6,  2])]\n",
      "[array([11,  6, 11,  5]), array([11,  6, 11, 10]), array([11,  6, 11, 13]), array([11,  9,  7]), array([11,  9, 14,  4]), array([11,  9,  1]), array([11,  6, 11, 10,  4]), array([11,  6, 11,  5,  4])]\n"
     ]
    }
   ],
   "source": [
    "Xtest = word_seq(x_test)\n",
    "print(Xtest)\n",
    "Xtrain = word_seq(words)\n",
    "print(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 11  6 11  5]\n",
      " [ 0 11  6 11 10]\n",
      " [ 0 11  6 11 13]\n",
      " [ 0  0 11  9  7]\n",
      " [ 0 11  9 14  4]\n",
      " [ 0  0 11  9  1]\n",
      " [11  6 11 10  4]\n",
      " [11  6 11  5  4]]\n"
     ]
    }
   ],
   "source": [
    "Xtrain = sequence.pad_sequences(np.array(Xtrain),padding='pre')\n",
    "print(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "intput_lenght = len(Xtrain[0])\n",
    "print(intput_lenght)\n",
    "vocab_size = len(vocab)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 11  6 11  3]\n",
      " [ 0 11  6 11 12]\n",
      " [ 0 11  6 11  8]\n",
      " [ 0  0 11  6  2]]\n"
     ]
    }
   ],
   "source": [
    "Xtest = sequence.pad_sequences(np.array(Xtest),maxlen=intput_lenght,padding='pre')\n",
    "print(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(input_dim = vocab_size,output_dim = 300,input_length=intput_lenght))\n",
    "model.add(keras.layers.Bidirectional(keras.layers.LSTM(12, return_sequences=True)))\n",
    "model.add(keras.layers.Bidirectional(keras.layers.LSTM(6)))\n",
    "model.add(keras.layers.Dense(12, activation=keras.activations.relu))\n",
    "model.add(keras.layers.Dense(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy, optimizer=keras.optimizers.SGD(learning_rate=1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 5, 300)            4800      \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 5, 24)             30048     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 12)                1488      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 2)                 26        \n",
      "=================================================================\n",
      "Total params: 36,518\n",
      "Trainable params: 36,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8036\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.6931\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6931\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6931\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.6931\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6931\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6931\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6931\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6931\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2151ecfd610>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain, np.array([1,1,1,0,0,0,1,1]), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(Xtrain).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(Xtest).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
